{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c9c094-5f16-4f18-97f1-38bad91cd6ac",
   "metadata": {},
   "source": [
    "# Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d7fc40-4dc9-47bf-8fd0-546dc64599b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 02:26:45.351377: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 02:27:16.835735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 02:27:17.242966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46662 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:75:01.0, compute capability: 8.9\n",
      "2024-05-19 02:27:50.261016: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-19 02:27:50.969541: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-19 02:27:50.969560: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-19 02:27:50.969608: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-19 02:27:51.642137: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157/1157 [==============================] - 401s 325ms/step - loss: 0.3777 - accuracy: 0.8351 - val_loss: 0.2151 - val_accuracy: 0.9089\n",
      "193/193 [==============================] - 36s 157ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.98      0.89      0.93      4434\n",
      "    landslide       0.77      0.96      0.86      1733\n",
      "\n",
      "     accuracy                           0.91      6167\n",
      "    macro avg       0.88      0.92      0.89      6167\n",
      " weighted avg       0.92      0.91      0.91      6167\n",
      "\n",
      "Accuracy: 0.9090\n",
      "Precision: 0.9237\n",
      "Recall: 0.9090\n",
      "F1 Score: 0.9117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input, Dropout, Conv2D, SeparableConv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Conv2D, Multiply, LayerNormalization, MultiHeadAttention, Add, Flatten\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "data_path = \"TrainData_3/TrainData_3\"\n",
    "img_size = (224, 224)\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "def spatial_attention_module(input_feature):\n",
    "    # 使用一个1x1的卷积层来生成注意力图\n",
    "    attention = Conv2D(1, (1, 1), activation='sigmoid')(input_feature)\n",
    "    # 将注意力图乘以原特征图来增强重要特征\n",
    "    enhanced_feature = Multiply()([input_feature, attention])\n",
    "    return enhanced_feature\n",
    "\n",
    "def build_image_model(input_shape):\n",
    "    img_input = Input(shape=input_shape, name='image_input')\n",
    "    img_base_model = EfficientNetB7(include_top=False, input_tensor=img_input, weights='imagenet')\n",
    "    img_features = img_base_model.output\n",
    "    img_features = spatial_attention_module(img_features)\n",
    "    img_features = GlobalAveragePooling2D()(img_features)\n",
    "    return Model(inputs=img_input, outputs=img_features, name='ImageModel')\n",
    "\n",
    "def load_images(folder, filenames, color_mode='rgb'):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        if filename.startswith('.'):  # 过滤掉隐藏文件\n",
    "            continue\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = load_img(img_path, target_size=img_size, color_mode=color_mode)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def transformer_block(x, num_heads=4):\n",
    "    # Layer Normalization\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    # Multi-head self-attention\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=64)(x_norm, x_norm)\n",
    "    # Skip connection\n",
    "    x = Add()([x, attn_output])\n",
    "    # Another layer normalization\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    # Feed-forward network\n",
    "    ff_output = Dense(units=512, activation='relu')(x_norm)\n",
    "    # Final skip connection\n",
    "    output = Add()([x, ff_output])\n",
    "    return output\n",
    "\n",
    "def prepare_dataset(data_path):\n",
    "    landslide_path = os.path.join(data_path, \"landslide\")\n",
    "    non_landslide_path = os.path.join(data_path, \"non-landslide\")\n",
    "    \n",
    "    landslide_filenames = [filename for filename in os.listdir(os.path.join(landslide_path, \"image\")) if not filename.startswith('.')]\n",
    "    non_landslide_filenames = [filename for filename in os.listdir(os.path.join(non_landslide_path, \"image\")) if not filename.startswith('.')]\n",
    "\n",
    "    landslide_images = load_images(os.path.join(landslide_path, \"image\"), landslide_filenames)\n",
    "    landslide_dems = load_images(os.path.join(landslide_path, \"dem\"), landslide_filenames, color_mode='grayscale')\n",
    "    non_landslide_images = load_images(os.path.join(non_landslide_path, \"image\"), non_landslide_filenames)\n",
    "    non_landslide_dems = load_images(os.path.join(non_landslide_path, \"dem\"), non_landslide_filenames, color_mode='grayscale')\n",
    "\n",
    "    landslide_labels = np.ones(len(landslide_filenames), dtype=int)\n",
    "    non_landslide_labels = np.zeros(len(non_landslide_filenames), dtype=int)\n",
    "\n",
    "    images = np.concatenate([landslide_images, non_landslide_images], axis=0)\n",
    "    dems = np.concatenate([landslide_dems, non_landslide_dems], axis=0)\n",
    "    labels = np.concatenate([landslide_labels, non_landslide_labels], axis=0)\n",
    "\n",
    "    return images, dems, labels\n",
    "\n",
    "\n",
    "images, dems, labels = prepare_dataset(data_path)\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "x_img_train, x_img_val, x_dem_train, x_dem_val, y_train, y_val = train_test_split(images, dems, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "def build_dem_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape, name='dem_input')\n",
    "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, -1))(x)\n",
    "    x = transformer_block(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=inputs, outputs=x, name='Advanced_DEM_CNN')\n",
    "\n",
    "\n",
    "def build_vae_feature_merger(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    z_mean = Dense(64)(x)\n",
    "    z_log_var = Dense(64)(x)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "    encoder = Model(input_layer, [z_mean, z_log_var, z], name='vae_merger')\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "# Build the dual input model\n",
    "def build_dual_input_model(input_shape):\n",
    "    img_model = build_image_model(input_shape)\n",
    "    img_features = img_model.output\n",
    "\n",
    "    dem_input_shape = (img_size[0], img_size[1], 1)  \n",
    "    dem_model = build_dem_cnn_model(dem_input_shape)\n",
    "    dem_features = dem_model.output\n",
    "\n",
    "    merged_features = Concatenate()([img_features, dem_features])\n",
    "    vae_encoder = build_vae_feature_merger(merged_features.shape[1])\n",
    "    z_mean, z_log_var, z = vae_encoder(merged_features)\n",
    "\n",
    "    x = Dense(256, activation='relu')(z)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[img_model.input, dem_model.input], outputs=output, name='DualInputModel')\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = build_dual_input_model(input_shape=(224, 224, 3))\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the checkpoint filepath\n",
    "checkpoint_filepath = 'best_model.h5'\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the ModelCheckpoint callback\n",
    "history = model.fit(\n",
    "    [x_img_train, x_dem_train],\n",
    "    y_train,\n",
    "    validation_data=([x_img_val, x_dem_val], y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    ")\n",
    "\n",
    "\n",
    "y_pred_probs = model.predict([x_img_val, x_dem_val])\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['non-landslide', 'landslide']))\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb46e91-195d-47c4-8793-a440f0daf4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 08:40:17.741172: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-20 08:40:50.110337: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-20 08:40:50.543555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46662 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:65:01.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 08:41:24.810777: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-20 08:41:25.540421: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-20 08:41:25.540441: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-20 08:41:25.540487: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-20 08:41:26.211057: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157/1157 [==============================] - 405s 328ms/step - loss: 0.3534 - accuracy: 0.8474 - val_loss: 1.1830 - val_accuracy: 0.7540\n",
      "Epoch 2/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.2071 - accuracy: 0.9203 - val_loss: 0.1662 - val_accuracy: 0.9330\n",
      "Epoch 3/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.1224 - accuracy: 0.9541 - val_loss: 0.1548 - val_accuracy: 0.9376\n",
      "Epoch 4/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 0.2102 - val_accuracy: 0.9335\n",
      "Epoch 5/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.0650 - accuracy: 0.9768 - val_loss: 0.1998 - val_accuracy: 0.9338\n",
      "Epoch 6/20\n",
      "1157/1157 [==============================] - 370s 320ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.1868 - val_accuracy: 0.9400\n",
      "Epoch 7/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.2409 - val_accuracy: 0.9353\n",
      "Epoch 8/20\n",
      "1157/1157 [==============================] - 370s 320ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.2026 - val_accuracy: 0.9398\n",
      "Epoch 9/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.2524 - val_accuracy: 0.9361\n",
      "Epoch 10/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 0.2222 - val_accuracy: 0.9371\n",
      "Epoch 11/20\n",
      "1157/1157 [==============================] - 368s 318ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 0.3484 - val_accuracy: 0.9397\n",
      "Epoch 12/20\n",
      "1157/1157 [==============================] - 369s 319ms/step - loss: 0.0325 - accuracy: 0.9903 - val_loss: 0.2054 - val_accuracy: 0.9407\n",
      "Epoch 13/20\n",
      "1157/1157 [==============================] - 367s 317ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.2449 - val_accuracy: 0.9387\n",
      "Epoch 14/20\n",
      "1157/1157 [==============================] - 368s 318ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 0.1960 - val_accuracy: 0.9462\n",
      "Epoch 15/20\n",
      "1157/1157 [==============================] - 368s 318ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.2206 - val_accuracy: 0.9460\n",
      "Epoch 16/20\n",
      "1157/1157 [==============================] - 368s 318ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 0.4291 - val_accuracy: 0.9347\n",
      "Epoch 17/20\n",
      "1157/1157 [==============================] - 368s 318ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.3229 - val_accuracy: 0.9353\n",
      "Epoch 18/20\n",
      "1157/1157 [==============================] - 367s 317ms/step - loss: 0.0365 - accuracy: 0.9899 - val_loss: 0.2843 - val_accuracy: 0.9436\n",
      "Epoch 19/20\n",
      "1157/1157 [==============================] - 366s 316ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.2546 - val_accuracy: 0.9385\n",
      "Epoch 20/20\n",
      "1157/1157 [==============================] - 367s 317ms/step - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.3603 - val_accuracy: 0.9471\n",
      "193/193 [==============================] - 36s 158ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.97      0.96      0.96      4434\n",
      "    landslide       0.90      0.91      0.91      1733\n",
      "\n",
      "     accuracy                           0.95      6167\n",
      "    macro avg       0.93      0.94      0.93      6167\n",
      " weighted avg       0.95      0.95      0.95      6167\n",
      "\n",
      "Accuracy: 0.9470\n",
      "Precision: 0.9473\n",
      "Recall: 0.9470\n",
      "F1 Score: 0.9471\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input, Dropout, Conv2D, SeparableConv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Conv2D, Multiply, LayerNormalization, MultiHeadAttention, Add, Flatten\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "data_path = \"TrainData_3/TrainData_3\"\n",
    "img_size = (224, 224)\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "def spatial_attention_module(input_feature):\n",
    "    # 使用一个1x1的卷积层来生成注意力图\n",
    "    attention = Conv2D(1, (1, 1), activation='sigmoid')(input_feature)\n",
    "    # 将注意力图乘以原特征图来增强重要特征\n",
    "    enhanced_feature = Multiply()([input_feature, attention])\n",
    "    return enhanced_feature\n",
    "\n",
    "def build_image_model(input_shape):\n",
    "    img_input = Input(shape=input_shape, name='image_input')\n",
    "    img_base_model = EfficientNetB7(include_top=False, input_tensor=img_input, weights='imagenet')\n",
    "    img_features = img_base_model.output\n",
    "    img_features = spatial_attention_module(img_features)\n",
    "    img_features = GlobalAveragePooling2D()(img_features)\n",
    "    return Model(inputs=img_input, outputs=img_features, name='ImageModel')\n",
    "\n",
    "def load_images(folder, filenames, color_mode='rgb'):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        if filename.startswith('.'):  # 过滤掉隐藏文件\n",
    "            continue\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = load_img(img_path, target_size=img_size, color_mode=color_mode)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def transformer_block(x, num_heads=4):\n",
    "    # Layer Normalization\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    # Multi-head self-attention\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=64)(x_norm, x_norm)\n",
    "    # Skip connection\n",
    "    x = Add()([x, attn_output])\n",
    "    # Another layer normalization\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    # Feed-forward network\n",
    "    ff_output = Dense(units=512, activation='relu')(x_norm)\n",
    "    # Final skip connection\n",
    "    output = Add()([x, ff_output])\n",
    "    return output\n",
    "\n",
    "def prepare_dataset(data_path):\n",
    "    landslide_path = os.path.join(data_path, \"landslide\")\n",
    "    non_landslide_path = os.path.join(data_path, \"non-landslide\")\n",
    "    \n",
    "    landslide_filenames = [filename for filename in os.listdir(os.path.join(landslide_path, \"image\")) if not filename.startswith('.')]\n",
    "    non_landslide_filenames = [filename for filename in os.listdir(os.path.join(non_landslide_path, \"image\")) if not filename.startswith('.')]\n",
    "\n",
    "    landslide_images = load_images(os.path.join(landslide_path, \"image\"), landslide_filenames)\n",
    "    landslide_dems = load_images(os.path.join(landslide_path, \"dem\"), landslide_filenames, color_mode='grayscale')\n",
    "    non_landslide_images = load_images(os.path.join(non_landslide_path, \"image\"), non_landslide_filenames)\n",
    "    non_landslide_dems = load_images(os.path.join(non_landslide_path, \"dem\"), non_landslide_filenames, color_mode='grayscale')\n",
    "\n",
    "    landslide_labels = np.ones(len(landslide_filenames), dtype=int)\n",
    "    non_landslide_labels = np.zeros(len(non_landslide_filenames), dtype=int)\n",
    "\n",
    "    images = np.concatenate([landslide_images, non_landslide_images], axis=0)\n",
    "    dems = np.concatenate([landslide_dems, non_landslide_dems], axis=0)\n",
    "    labels = np.concatenate([landslide_labels, non_landslide_labels], axis=0)\n",
    "\n",
    "    return images, dems, labels\n",
    "\n",
    "\n",
    "images, dems, labels = prepare_dataset(data_path)\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "x_img_train, x_img_val, x_dem_train, x_dem_val, y_train, y_val = train_test_split(images, dems, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "def build_dem_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape, name='dem_input')\n",
    "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, -1))(x)\n",
    "    x = transformer_block(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=inputs, outputs=x, name='Advanced_DEM_CNN')\n",
    "\n",
    "\n",
    "def build_vae_feature_merger(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    z_mean = Dense(64)(x)\n",
    "    z_log_var = Dense(64)(x)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "    encoder = Model(input_layer, [z_mean, z_log_var, z], name='vae_merger')\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "# Build the dual input model\n",
    "def build_dual_input_model(input_shape):\n",
    "    img_model = build_image_model(input_shape)\n",
    "    img_features = img_model.output\n",
    "\n",
    "    dem_input_shape = (img_size[0], img_size[1], 1)  \n",
    "    dem_model = build_dem_cnn_model(dem_input_shape)\n",
    "    dem_features = dem_model.output\n",
    "\n",
    "    merged_features = Concatenate()([img_features, dem_features])\n",
    "    vae_encoder = build_vae_feature_merger(merged_features.shape[1])\n",
    "    z_mean, z_log_var, z = vae_encoder(merged_features)\n",
    "\n",
    "    x = Dense(256, activation='relu')(z)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[img_model.input, dem_model.input], outputs=output, name='DualInputModel')\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = build_dual_input_model(input_shape=(224, 224, 3))\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the checkpoint filepath\n",
    "checkpoint_filepath = 'best_model.h5'\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the ModelCheckpoint callback\n",
    "history = model.fit(\n",
    "    [x_img_train, x_dem_train],\n",
    "    y_train,\n",
    "    validation_data=([x_img_val, x_dem_val], y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    ")\n",
    "\n",
    "\n",
    "y_pred_probs = model.predict([x_img_val, x_dem_val])\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['non-landslide', 'landslide']))\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20306aa7-789d-4964-8d59-d0d9cf1ec269",
   "metadata": {},
   "source": [
    "## Other Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fcd73c-fad1-4fef-8193-179494b9e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 5s 0us/step\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 38s 97ms/step - loss: 11.3002 - accuracy: 0.8763 - val_loss: 0.3572 - val_accuracy: 0.8342\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 26s 84ms/step - loss: 0.2327 - accuracy: 0.9123 - val_loss: 0.2395 - val_accuracy: 0.8954\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 25s 82ms/step - loss: 0.2560 - accuracy: 0.9102 - val_loss: 0.2226 - val_accuracy: 0.8983\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 24s 78ms/step - loss: 0.1928 - accuracy: 0.9226 - val_loss: 0.5469 - val_accuracy: 0.7921\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 25s 81ms/step - loss: 0.1738 - accuracy: 0.9287 - val_loss: 0.8562 - val_accuracy: 0.7110\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 24s 76ms/step - loss: 0.1684 - accuracy: 0.9319 - val_loss: 0.2431 - val_accuracy: 0.9031\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.1613 - accuracy: 0.9329 - val_loss: 0.4119 - val_accuracy: 0.8237\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.6087 - accuracy: 0.9275 - val_loss: 0.2550 - val_accuracy: 0.8987\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.2086 - accuracy: 0.9364 - val_loss: 0.3209 - val_accuracy: 0.8893\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.1431 - accuracy: 0.9401 - val_loss: 0.4451 - val_accuracy: 0.8330\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 23s 76ms/step - loss: 0.1261 - accuracy: 0.9465 - val_loss: 0.5881 - val_accuracy: 0.7815\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 24s 78ms/step - loss: 0.1198 - accuracy: 0.9494 - val_loss: 0.2467 - val_accuracy: 0.8829\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 24s 77ms/step - loss: 0.1083 - accuracy: 0.9572 - val_loss: 0.2623 - val_accuracy: 0.9019\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0954 - accuracy: 0.9630 - val_loss: 0.2124 - val_accuracy: 0.9076\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 24s 76ms/step - loss: 0.1881 - accuracy: 0.9513 - val_loss: 0.2839 - val_accuracy: 0.8861\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 24s 77ms/step - loss: 0.0930 - accuracy: 0.9644 - val_loss: 0.2649 - val_accuracy: 0.9133\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0667 - accuracy: 0.9737 - val_loss: 0.2806 - val_accuracy: 0.9104\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 24s 76ms/step - loss: 0.0577 - accuracy: 0.9782 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 24s 76ms/step - loss: 0.1278 - accuracy: 0.9750 - val_loss: 0.4338 - val_accuracy: 0.8683\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0507 - accuracy: 0.9811 - val_loss: 0.3780 - val_accuracy: 0.9076\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 24s 77ms/step - loss: 0.0591 - accuracy: 0.9775 - val_loss: 0.3715 - val_accuracy: 0.8715\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 24s 78ms/step - loss: 0.0401 - accuracy: 0.9856 - val_loss: 0.3445 - val_accuracy: 0.9039\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 24s 77ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.2913 - val_accuracy: 0.9124\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.1969 - accuracy: 0.9761 - val_loss: 0.4182 - val_accuracy: 0.8910\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 25s 81ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.6173 - val_accuracy: 0.8760\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.4160 - val_accuracy: 0.9141\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 24s 79ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.4017 - val_accuracy: 0.9165\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 24s 77ms/step - loss: 0.0440 - accuracy: 0.9841 - val_loss: 0.8383 - val_accuracy: 0.8375\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.5016 - val_accuracy: 0.8914\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.3715 - val_accuracy: 0.9116\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 25s 79ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.3501 - val_accuracy: 0.9047\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 23s 76ms/step - loss: 1.1390 - accuracy: 0.9516 - val_loss: 0.3087 - val_accuracy: 0.9035\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.4631 - accuracy: 0.9508 - val_loss: 0.3277 - val_accuracy: 0.8776\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.1625 - accuracy: 0.9498 - val_loss: 0.5031 - val_accuracy: 0.8930\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.1195 - accuracy: 0.9824 - val_loss: 0.4495 - val_accuracy: 0.8995\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 24s 78ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.3898 - val_accuracy: 0.9128\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.4643 - val_accuracy: 0.9173\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.6426 - val_accuracy: 0.8995\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.5001 - val_accuracy: 0.9096\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 1.2300 - val_accuracy: 0.8816\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 24s 77ms/step - loss: 0.0606 - accuracy: 0.9795 - val_loss: 0.3693 - val_accuracy: 0.9047\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.4867 - val_accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.4757 - val_accuracy: 0.9116\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.4346 - val_accuracy: 0.8849\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0206 - accuracy: 0.9917 - val_loss: 0.6837 - val_accuracy: 0.8991\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.4902 - val_accuracy: 0.9092\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 23s 75ms/step - loss: 0.0479 - accuracy: 0.9913 - val_loss: 0.4636 - val_accuracy: 0.9137\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 23s 76ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.5209 - val_accuracy: 0.9068\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0195 - accuracy: 0.9924 - val_loss: 2.2898 - val_accuracy: 0.7985\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 23s 74ms/step - loss: 0.0127 - accuracy: 0.9946 - val_loss: 1.5120 - val_accuracy: 0.8443\n",
      "97/97 - 3s - loss: 1.7370 - accuracy: 0.8440 - 3s/epoch - 26ms/step\n",
      "\n",
      "Test accuracy: 0.8440337181091309\n",
      "97/97 [==============================] - 3s 21ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.83      0.99      0.90      2208\n",
      "    landslide       0.95      0.47      0.63       876\n",
      "\n",
      "     accuracy                           0.84      3084\n",
      "    macro avg       0.89      0.73      0.77      3084\n",
      " weighted avg       0.86      0.84      0.83      3084\n",
      "\n",
      "Accuracy: 0.6547525322109343\n",
      "Precision: 0.4748858447488584\n",
      "Recall: 0.4748858447488584\n",
      "F1 Score: 0.4748858447488584\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用ResNet50）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = ResNet50(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用简单的CNN模型）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(input_dem)\n",
    "dem_pool1 = MaxPooling2D(pool_size=(2, 2))(dem_conv1)\n",
    "dem_conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(dem_pool1)\n",
    "dem_pool2 = MaxPooling2D(pool_size=(2, 2))(dem_conv2)\n",
    "dem_flat = Flatten()(dem_pool2)\n",
    "dem_output = Dense(256, activation='relu')(dem_flat)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfa415e-fbff-47e9-adbb-3a4ac036bef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 5s 0us/step\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 57s 153ms/step - loss: 2.3900 - accuracy: 0.8132 - val_loss: 0.3109 - val_accuracy: 0.8573\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 42s 135ms/step - loss: 0.2918 - accuracy: 0.8702 - val_loss: 4.8118 - val_accuracy: 0.7175\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 42s 135ms/step - loss: 0.2692 - accuracy: 0.8860 - val_loss: 0.3038 - val_accuracy: 0.8553\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 42s 135ms/step - loss: 0.2478 - accuracy: 0.8953 - val_loss: 0.2296 - val_accuracy: 0.9072\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 42s 135ms/step - loss: 0.2332 - accuracy: 0.8974 - val_loss: 0.2422 - val_accuracy: 0.8881\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.2272 - accuracy: 0.9020 - val_loss: 0.2299 - val_accuracy: 0.8999\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.2277 - accuracy: 0.9017 - val_loss: 0.2050 - val_accuracy: 0.9080\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.2145 - accuracy: 0.9080 - val_loss: 0.2056 - val_accuracy: 0.9124\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.2010 - accuracy: 0.9139 - val_loss: 0.2074 - val_accuracy: 0.9039\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.1941 - accuracy: 0.9153 - val_loss: 2.2915 - val_accuracy: 0.7175\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 42s 135ms/step - loss: 0.1932 - accuracy: 0.9197 - val_loss: 0.2140 - val_accuracy: 0.9068\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1963 - accuracy: 0.9155 - val_loss: 0.2197 - val_accuracy: 0.9015\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 41s 134ms/step - loss: 0.1867 - accuracy: 0.9200 - val_loss: 0.2030 - val_accuracy: 0.9080\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1769 - accuracy: 0.9254 - val_loss: 0.1993 - val_accuracy: 0.9185\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 41s 134ms/step - loss: 0.1787 - accuracy: 0.9219 - val_loss: 0.2055 - val_accuracy: 0.9072\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1800 - accuracy: 0.9228 - val_loss: 0.1959 - val_accuracy: 0.9153\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1668 - accuracy: 0.9269 - val_loss: 0.1833 - val_accuracy: 0.9181\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.1689 - accuracy: 0.9269 - val_loss: 0.2479 - val_accuracy: 0.8922\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.1732 - accuracy: 0.9256 - val_loss: 0.2411 - val_accuracy: 0.8983\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 41s 134ms/step - loss: 0.1739 - accuracy: 0.9267 - val_loss: 0.1860 - val_accuracy: 0.9141\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1605 - accuracy: 0.9320 - val_loss: 0.2676 - val_accuracy: 0.8914\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1698 - accuracy: 0.9242 - val_loss: 0.1903 - val_accuracy: 0.9234\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.1641 - accuracy: 0.9287 - val_loss: 0.1921 - val_accuracy: 0.9169\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1524 - accuracy: 0.9332 - val_loss: 0.1910 - val_accuracy: 0.9173\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.1558 - accuracy: 0.9325 - val_loss: 0.2296 - val_accuracy: 0.9072\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1558 - accuracy: 0.9327 - val_loss: 0.1843 - val_accuracy: 0.9189\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.1478 - accuracy: 0.9381 - val_loss: 0.1976 - val_accuracy: 0.9153\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1725 - accuracy: 0.9273 - val_loss: 0.1966 - val_accuracy: 0.9133\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.1617 - accuracy: 0.9312 - val_loss: 0.2044 - val_accuracy: 0.9108\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.1370 - accuracy: 0.9430 - val_loss: 0.1724 - val_accuracy: 0.9287\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1314 - accuracy: 0.9462 - val_loss: 0.1839 - val_accuracy: 0.9206\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.1709 - accuracy: 0.9292 - val_loss: 0.3842 - val_accuracy: 0.8281\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1758 - accuracy: 0.9242 - val_loss: 0.2094 - val_accuracy: 0.9088\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1434 - accuracy: 0.9389 - val_loss: 0.2384 - val_accuracy: 0.9084\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.1490 - accuracy: 0.9367 - val_loss: 0.2208 - val_accuracy: 0.9023\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.1831 - accuracy: 0.9311 - val_loss: 0.2268 - val_accuracy: 0.9003\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1651 - accuracy: 0.9295 - val_loss: 0.1949 - val_accuracy: 0.9181\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.1525 - accuracy: 0.9386 - val_loss: 0.4561 - val_accuracy: 0.8942\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1644 - accuracy: 0.9312 - val_loss: 0.1998 - val_accuracy: 0.9250\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.1188 - accuracy: 0.9516 - val_loss: 0.2101 - val_accuracy: 0.9169\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.1098 - accuracy: 0.9531 - val_loss: 0.2178 - val_accuracy: 0.9226\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1004 - accuracy: 0.9584 - val_loss: 0.2496 - val_accuracy: 0.9068\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.1064 - accuracy: 0.9594 - val_loss: 0.2191 - val_accuracy: 0.9112\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.0920 - accuracy: 0.9633 - val_loss: 0.2211 - val_accuracy: 0.9177\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.0811 - accuracy: 0.9677 - val_loss: 0.2525 - val_accuracy: 0.9145\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.0894 - accuracy: 0.9642 - val_loss: 0.3105 - val_accuracy: 0.8987\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.0926 - accuracy: 0.9640 - val_loss: 0.2705 - val_accuracy: 0.9043\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 42s 134ms/step - loss: 0.1179 - accuracy: 0.9552 - val_loss: 0.2596 - val_accuracy: 0.9084\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.0645 - accuracy: 0.9748 - val_loss: 0.2678 - val_accuracy: 0.9169\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.0637 - accuracy: 0.9746 - val_loss: 0.2369 - val_accuracy: 0.9120\n",
      "97/97 - 4s - loss: 0.2803 - accuracy: 0.9076 - 4s/epoch - 45ms/step\n",
      "\n",
      "Test accuracy: 0.9075875282287598\n",
      "97/97 [==============================] - 5s 36ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.93      0.94      0.94      2208\n",
      "    landslide       0.84      0.83      0.84       876\n",
      "\n",
      "     accuracy                           0.91      3084\n",
      "    macro avg       0.89      0.88      0.89      3084\n",
      " weighted avg       0.91      0.91      0.91      3084\n",
      "\n",
      "Accuracy: 0.5945320898121091\n",
      "Precision: 0.8321917808219178\n",
      "Recall: 0.8321917808219178\n",
      "F1 Score: 0.8321917808219178\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用VGG16）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = VGG16(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用InceptionV3）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973ef10a-e7bb-4ccb-b567-4d6f56454e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 09:31:23.265574: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 09:32:00.046495: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 09:32:00.539340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46662 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:65:01.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 09:32:23.595578: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-19 09:32:24.284074: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-19 09:32:24.284093: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-19 09:32:24.284144: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-19 09:32:25.087762: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 61s 161ms/step - loss: 0.2867 - accuracy: 0.8784 - val_loss: 1.3652 - val_accuracy: 0.8245\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 48s 156ms/step - loss: 0.2176 - accuracy: 0.9070 - val_loss: 0.6942 - val_accuracy: 0.8553\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 48s 156ms/step - loss: 0.2081 - accuracy: 0.9119 - val_loss: 0.2233 - val_accuracy: 0.9104\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1922 - accuracy: 0.9222 - val_loss: 0.2421 - val_accuracy: 0.8970\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.1811 - accuracy: 0.9256 - val_loss: 0.2313 - val_accuracy: 0.8946\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.1788 - accuracy: 0.9241 - val_loss: 0.5734 - val_accuracy: 0.8180\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.1691 - accuracy: 0.9276 - val_loss: 0.2839 - val_accuracy: 0.8926\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.1566 - accuracy: 0.9344 - val_loss: 0.3808 - val_accuracy: 0.9011\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.1472 - accuracy: 0.9387 - val_loss: 0.1928 - val_accuracy: 0.9153\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.1311 - accuracy: 0.9455 - val_loss: 0.4606 - val_accuracy: 0.8443\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.1338 - accuracy: 0.9467 - val_loss: 0.4621 - val_accuracy: 0.8756\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.1189 - accuracy: 0.9526 - val_loss: 0.2346 - val_accuracy: 0.9051\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.1030 - accuracy: 0.9585 - val_loss: 1.3226 - val_accuracy: 0.7495\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0946 - accuracy: 0.9626 - val_loss: 1.4825 - val_accuracy: 0.7929\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.0816 - accuracy: 0.9703 - val_loss: 0.2622 - val_accuracy: 0.9141\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 48s 156ms/step - loss: 0.0636 - accuracy: 0.9770 - val_loss: 0.4149 - val_accuracy: 0.8638\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0537 - accuracy: 0.9804 - val_loss: 0.3475 - val_accuracy: 0.9027\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0562 - accuracy: 0.9801 - val_loss: 0.3220 - val_accuracy: 0.8938\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.0398 - accuracy: 0.9855 - val_loss: 0.4113 - val_accuracy: 0.8808\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.0432 - accuracy: 0.9843 - val_loss: 0.7330 - val_accuracy: 0.8606\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 0.4987 - val_accuracy: 0.8954\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0375 - accuracy: 0.9857 - val_loss: 0.5227 - val_accuracy: 0.8942\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.4372 - val_accuracy: 0.9072\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.3881 - val_accuracy: 0.9153\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0341 - accuracy: 0.9880 - val_loss: 0.3184 - val_accuracy: 0.9145\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.3901 - val_accuracy: 0.9031\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.5973 - val_accuracy: 0.8934\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.6202 - val_accuracy: 0.8646\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 2.0107 - val_accuracy: 0.7377\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.4279 - val_accuracy: 0.9210\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.3734 - val_accuracy: 0.9003\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0174 - accuracy: 0.9934 - val_loss: 0.8834 - val_accuracy: 0.8338\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.3574 - val_accuracy: 0.9007\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 48s 156ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.4162 - val_accuracy: 0.9104\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.3783 - val_accuracy: 0.9133\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.4874 - val_accuracy: 0.8974\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.7523 - val_accuracy: 0.8808\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.4699 - val_accuracy: 0.9092\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.3976 - val_accuracy: 0.9047\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5879 - val_accuracy: 0.9023\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.4653 - val_accuracy: 0.9141\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6779 - val_accuracy: 0.8995\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.4509 - val_accuracy: 0.8893\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.5063 - val_accuracy: 0.9019\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.5702 - val_accuracy: 0.9076\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 0.4428 - val_accuracy: 0.8877\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.5522 - val_accuracy: 0.9112\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.6112 - val_accuracy: 0.9031\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.4761 - val_accuracy: 0.9169\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.3895 - val_accuracy: 0.9161\n",
      "97/97 - 3s - loss: 0.4001 - accuracy: 0.9180 - 3s/epoch - 33ms/step\n",
      "\n",
      "Test accuracy: 0.9179636836051941\n",
      "97/97 [==============================] - 4s 28ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.95      0.94      0.94      2208\n",
      "    landslide       0.84      0.87      0.86       876\n",
      "\n",
      "     accuracy                           0.92      3084\n",
      "    macro avg       0.90      0.90      0.90      3084\n",
      " weighted avg       0.92      0.92      0.92      3084\n",
      "\n",
      "Accuracy: 0.588650093112689\n",
      "Precision: 0.8744292237442922\n",
      "Recall: 0.8744292237442922\n",
      "F1 Score: 0.8744292237442923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用ResNet50）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = ResNet50(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用MobileNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46e7bea-2180-455d-952c-4d3e55ca7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 5s 0us/step\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 94s 274ms/step - loss: 0.2638 - accuracy: 0.8889 - val_loss: 2.6321 - val_accuracy: 0.6019\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 82s 266ms/step - loss: 0.2156 - accuracy: 0.9086 - val_loss: 3.3888 - val_accuracy: 0.4795\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 82s 267ms/step - loss: 0.1952 - accuracy: 0.9150 - val_loss: 2.4905 - val_accuracy: 0.5517\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 83s 268ms/step - loss: 0.1724 - accuracy: 0.9320 - val_loss: 0.3643 - val_accuracy: 0.8950\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 81s 262ms/step - loss: 0.1517 - accuracy: 0.9378 - val_loss: 3.3872 - val_accuracy: 0.3518\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 81s 261ms/step - loss: 0.1539 - accuracy: 0.9356 - val_loss: 1.8792 - val_accuracy: 0.5987\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 81s 262ms/step - loss: 0.1402 - accuracy: 0.9434 - val_loss: 2.4292 - val_accuracy: 0.6907\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 81s 262ms/step - loss: 0.1340 - accuracy: 0.9489 - val_loss: 1.5218 - val_accuracy: 0.7215\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 80s 260ms/step - loss: 0.1158 - accuracy: 0.9526 - val_loss: 11.9352 - val_accuracy: 0.2825\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 81s 264ms/step - loss: 0.1075 - accuracy: 0.9589 - val_loss: 0.9397 - val_accuracy: 0.7523\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 82s 264ms/step - loss: 0.0978 - accuracy: 0.9614 - val_loss: 4.2711 - val_accuracy: 0.4013\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 81s 261ms/step - loss: 0.0806 - accuracy: 0.9698 - val_loss: 17.5943 - val_accuracy: 0.2829\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 80s 258ms/step - loss: 0.0756 - accuracy: 0.9718 - val_loss: 2.8301 - val_accuracy: 0.6680\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 80s 260ms/step - loss: 0.0776 - accuracy: 0.9694 - val_loss: 9.8473 - val_accuracy: 0.2870\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 80s 261ms/step - loss: 0.0716 - accuracy: 0.9730 - val_loss: 17.5093 - val_accuracy: 0.2825\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 80s 259ms/step - loss: 0.0607 - accuracy: 0.9786 - val_loss: 27.0065 - val_accuracy: 0.2829\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 80s 259ms/step - loss: 0.0605 - accuracy: 0.9795 - val_loss: 2.9248 - val_accuracy: 0.5975\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 80s 259ms/step - loss: 0.0505 - accuracy: 0.9791 - val_loss: 7.5857 - val_accuracy: 0.4037\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 80s 260ms/step - loss: 0.0440 - accuracy: 0.9834 - val_loss: 4.8152 - val_accuracy: 0.5671\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 80s 258ms/step - loss: 0.0416 - accuracy: 0.9863 - val_loss: 4.5145 - val_accuracy: 0.4820\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.0565 - accuracy: 0.9796 - val_loss: 4.3994 - val_accuracy: 0.4471\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 77s 249ms/step - loss: 0.0576 - accuracy: 0.9780 - val_loss: 3.8208 - val_accuracy: 0.5618\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 78s 251ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 6.0139 - val_accuracy: 0.4572\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 2.0712 - val_accuracy: 0.7260\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 76s 247ms/step - loss: 0.0469 - accuracy: 0.9819 - val_loss: 3.3904 - val_accuracy: 0.6765\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 2.3161 - val_accuracy: 0.6729\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 3.2194 - val_accuracy: 0.6182\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 77s 249ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.6923 - val_accuracy: 0.8934\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 4.4959 - val_accuracy: 0.5606\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 76s 246ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 5.5177 - val_accuracy: 0.5314\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 5.2791 - val_accuracy: 0.3575\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 3.4021 - val_accuracy: 0.6453\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 76s 247ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 15.5297 - val_accuracy: 0.2939\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 0.8199 - val_accuracy: 0.7280\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.7301 - val_accuracy: 0.8452\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.8471 - val_accuracy: 0.8808\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.4723 - val_accuracy: 0.9015\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 77s 251ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.4636 - val_accuracy: 0.8958\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 77s 248ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.5209 - val_accuracy: 0.8987\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 76s 246ms/step - loss: 0.0186 - accuracy: 0.9925 - val_loss: 0.8816 - val_accuracy: 0.8991\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.5751 - val_accuracy: 0.8537\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.6045 - val_accuracy: 0.9047\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 77s 249ms/step - loss: 0.0203 - accuracy: 0.9920 - val_loss: 0.6104 - val_accuracy: 0.9064\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.6099 - val_accuracy: 0.9035\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.9322 - val_accuracy: 0.8164\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.7488 - val_accuracy: 0.8614\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.8742 - val_accuracy: 0.8829\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.7682 - val_accuracy: 0.9035\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 77s 248ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 1.2165 - val_accuracy: 0.8634\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.8393 - val_accuracy: 0.8857\n",
      "97/97 - 3s - loss: 0.7535 - accuracy: 0.8975 - 3s/epoch - 35ms/step\n",
      "\n",
      "Test accuracy: 0.8975356817245483\n",
      "97/97 [==============================] - 4s 31ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.90      0.97      0.93      2208\n",
      "    landslide       0.91      0.71      0.80       876\n",
      "\n",
      "     accuracy                           0.90      3084\n",
      "    macro avg       0.90      0.84      0.86      3084\n",
      " weighted avg       0.90      0.90      0.89      3084\n",
      "\n",
      "Accuracy: 0.6193205044739512\n",
      "Precision: 0.7134703196347032\n",
      "Recall: 0.7134703196347032\n",
      "F1 Score: 0.7134703196347032\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNetV2）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用Xception）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = Xception(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68baa887-63ea-4399-b8dd-dfdfd4d769e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 14:25:02.020963: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 14:25:38.071579: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 14:25:38.423847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46662 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:65:01.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17225924/17225924 [==============================] - 7s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 5s 0us/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 14:26:17.398273: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-19 14:26:18.088751: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-19 14:26:18.088771: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-19 14:26:18.088822: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-19 14:26:18.803243: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 70s 175ms/step - loss: 0.2705 - accuracy: 0.8922 - val_loss: 1.3282 - val_accuracy: 0.6773\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 49s 159ms/step - loss: 0.1935 - accuracy: 0.9223 - val_loss: 0.2277 - val_accuracy: 0.9064\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.1669 - accuracy: 0.9337 - val_loss: 0.3083 - val_accuracy: 0.9019\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.1528 - accuracy: 0.9403 - val_loss: 0.5149 - val_accuracy: 0.8273\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.1326 - accuracy: 0.9484 - val_loss: 0.2159 - val_accuracy: 0.9262\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.1085 - accuracy: 0.9556 - val_loss: 0.2427 - val_accuracy: 0.9092\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.0943 - accuracy: 0.9642 - val_loss: 0.2564 - val_accuracy: 0.9226\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0964 - accuracy: 0.9628 - val_loss: 0.2460 - val_accuracy: 0.9283\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0729 - accuracy: 0.9721 - val_loss: 0.2718 - val_accuracy: 0.9222\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0693 - accuracy: 0.9742 - val_loss: 0.3800 - val_accuracy: 0.8837\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.4329 - val_accuracy: 0.8833\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0537 - accuracy: 0.9793 - val_loss: 0.2711 - val_accuracy: 0.9201\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 0.2415 - val_accuracy: 0.9278\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0345 - accuracy: 0.9873 - val_loss: 0.2880 - val_accuracy: 0.9169\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0417 - accuracy: 0.9855 - val_loss: 0.4090 - val_accuracy: 0.9043\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.2667 - val_accuracy: 0.9307\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.4224 - val_accuracy: 0.9128\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.3517 - val_accuracy: 0.9295\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0276 - accuracy: 0.9899 - val_loss: 0.4076 - val_accuracy: 0.9169\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.3170 - val_accuracy: 0.9270\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.2513 - val_accuracy: 0.9278\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.4578 - val_accuracy: 0.9246\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.3901 - val_accuracy: 0.9234\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0306 - accuracy: 0.9884 - val_loss: 0.3256 - val_accuracy: 0.9206\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0341 - accuracy: 0.9870 - val_loss: 0.4524 - val_accuracy: 0.9165\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.3526 - val_accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.0223 - accuracy: 0.9914 - val_loss: 0.3894 - val_accuracy: 0.9153\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.3727 - val_accuracy: 0.8910\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5579 - val_accuracy: 0.9035\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.5218 - val_accuracy: 0.9169\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.3828 - val_accuracy: 0.9210\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 0.4827 - val_accuracy: 0.9185\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.2874 - val_accuracy: 0.9222\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.3733 - val_accuracy: 0.9262\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.3877 - val_accuracy: 0.9335\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.3696 - val_accuracy: 0.9120\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.2535 - val_accuracy: 0.9185\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.3610 - val_accuracy: 0.9283\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.3092 - val_accuracy: 0.9266\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.3699 - val_accuracy: 0.9364\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.4828 - val_accuracy: 0.9234\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.3858 - val_accuracy: 0.9319\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.3389 - val_accuracy: 0.9274\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.5318 - val_accuracy: 0.9153\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.3786 - val_accuracy: 0.9355\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.3464 - val_accuracy: 0.9274\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.5720 - val_accuracy: 0.9246\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.3536 - val_accuracy: 0.9291\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.5231 - val_accuracy: 0.9108\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.4292 - val_accuracy: 0.9278\n",
      "97/97 - 3s - loss: 0.4002 - accuracy: 0.9306 - 3s/epoch - 33ms/step\n",
      "\n",
      "Test accuracy: 0.9306095838546753\n",
      "97/97 [==============================] - 4s 27ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.94      0.97      0.95      2208\n",
      "    landslide       0.91      0.84      0.87       876\n",
      "\n",
      "     accuracy                           0.93      3084\n",
      "    macro avg       0.92      0.90      0.91      3084\n",
      " weighted avg       0.93      0.93      0.93      3084\n",
      "\n",
      "Accuracy: 0.6027948946993898\n",
      "Precision: 0.839041095890411\n",
      "Recall: 0.839041095890411\n",
      "F1 Score: 0.839041095890411\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, DenseNet121\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNet）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNet(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用DenseNet121）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0543c36-268c-4c87-b762-bc08f797268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219055592/219055592 [==============================] - 26s 0us/step\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 83s 210ms/step - loss: 0.2595 - accuracy: 0.8937 - val_loss: 1.9111 - val_accuracy: 0.4706\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 59s 189ms/step - loss: 0.2105 - accuracy: 0.9113 - val_loss: 1.1766 - val_accuracy: 0.7353\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.1807 - accuracy: 0.9246 - val_loss: 2.4834 - val_accuracy: 0.5687\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 58s 189ms/step - loss: 0.1656 - accuracy: 0.9335 - val_loss: 0.5414 - val_accuracy: 0.8687\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.1567 - accuracy: 0.9351 - val_loss: 1.0611 - val_accuracy: 0.8034\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.1434 - accuracy: 0.9415 - val_loss: 0.8022 - val_accuracy: 0.8176\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 60s 193ms/step - loss: 0.1315 - accuracy: 0.9455 - val_loss: 0.9556 - val_accuracy: 0.6660\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.1290 - accuracy: 0.9495 - val_loss: 1.0690 - val_accuracy: 0.7681\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.1197 - accuracy: 0.9537 - val_loss: 1.6561 - val_accuracy: 0.5217\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.1008 - accuracy: 0.9608 - val_loss: 2.0666 - val_accuracy: 0.5999\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 58s 189ms/step - loss: 0.0966 - accuracy: 0.9630 - val_loss: 2.6909 - val_accuracy: 0.5148\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 59s 191ms/step - loss: 0.0894 - accuracy: 0.9665 - val_loss: 2.2373 - val_accuracy: 0.6400\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0764 - accuracy: 0.9691 - val_loss: 10.9606 - val_accuracy: 0.3008\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0698 - accuracy: 0.9745 - val_loss: 4.4963 - val_accuracy: 0.5099\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0603 - accuracy: 0.9767 - val_loss: 6.5005 - val_accuracy: 0.3668\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0510 - accuracy: 0.9809 - val_loss: 6.4442 - val_accuracy: 0.4447\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 7.8239 - val_accuracy: 0.3802\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0654 - accuracy: 0.9754 - val_loss: 8.6249 - val_accuracy: 0.3498\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 8.5421 - val_accuracy: 0.3340\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0518 - accuracy: 0.9812 - val_loss: 0.6594 - val_accuracy: 0.8366\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0503 - accuracy: 0.9803 - val_loss: 9.5267 - val_accuracy: 0.2919\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0381 - accuracy: 0.9853 - val_loss: 4.9615 - val_accuracy: 0.4694\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 3.2207 - val_accuracy: 0.5622\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 6.4438 - val_accuracy: 0.4710\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 59s 191ms/step - loss: 0.0423 - accuracy: 0.9845 - val_loss: 1.2668 - val_accuracy: 0.8192\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 1.8337 - val_accuracy: 0.6384\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 276.6312 - val_accuracy: 0.2825\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 58s 189ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 4.8001 - val_accuracy: 0.4929\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 58s 189ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 1.1949 - val_accuracy: 0.8237\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 58s 187ms/step - loss: 0.0253 - accuracy: 0.9905 - val_loss: 1.1146 - val_accuracy: 0.8589\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 3.1147 - val_accuracy: 0.5493\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 59s 191ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 1.5476 - val_accuracy: 0.7754\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0351 - accuracy: 0.9880 - val_loss: 3.9344 - val_accuracy: 0.6323\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.6138 - val_accuracy: 0.8901\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 59s 191ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.6743 - val_accuracy: 0.8906\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 58s 187ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.6326 - val_accuracy: 0.8739\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 2.4687 - val_accuracy: 0.6980\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 59s 189ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 1.2925 - val_accuracy: 0.8581\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 1.3558 - val_accuracy: 0.8626\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 60s 193ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.5398 - val_accuracy: 0.8922\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 1.6757 - val_accuracy: 0.8520\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.5342 - val_accuracy: 0.9035\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 59s 189ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 1.0685 - val_accuracy: 0.8257\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 1.9959 - val_accuracy: 0.7422\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 1.1595 - val_accuracy: 0.8370\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 58s 189ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 2.5289 - val_accuracy: 0.6652\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 58s 187ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.8593 - val_accuracy: 0.8780\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 59s 192ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.3839 - val_accuracy: 0.8618\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 58s 188ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 1.0241 - val_accuracy: 0.8760\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 59s 190ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.7839 - val_accuracy: 0.8484\n",
      "97/97 - 4s - loss: 0.8555 - accuracy: 0.8427 - 4s/epoch - 44ms/step\n",
      "\n",
      "Test accuracy: 0.8427367210388184\n",
      "97/97 [==============================] - 7s 42ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.94      0.83      0.88      2208\n",
      "    landslide       0.67      0.87      0.76       876\n",
      "\n",
      "     accuracy                           0.84      3084\n",
      "    macro avg       0.81      0.85      0.82      3084\n",
      " weighted avg       0.87      0.84      0.85      3084\n",
      "\n",
      "Accuracy: 0.5564391588063408\n",
      "Precision: 0.8732876712328768\n",
      "Recall: 0.8732876712328768\n",
      "F1 Score: 0.8732876712328768\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, InceptionResNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNetV2）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用InceptionResNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d5692d-81d5-4ae2-9858-741b7288e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "309/309 [==============================] - 65s 162ms/step - loss: 1.3283 - accuracy: 0.8892 - val_loss: 1.1094 - val_accuracy: 0.8208\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.2157 - accuracy: 0.9100 - val_loss: 0.2217 - val_accuracy: 0.8979\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1958 - accuracy: 0.9169 - val_loss: 0.3974 - val_accuracy: 0.8606\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1922 - accuracy: 0.9180 - val_loss: 0.1971 - val_accuracy: 0.9153\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.1816 - accuracy: 0.9240 - val_loss: 0.2187 - val_accuracy: 0.9051\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1786 - accuracy: 0.9222 - val_loss: 0.2316 - val_accuracy: 0.9007\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.1687 - accuracy: 0.9277 - val_loss: 0.3336 - val_accuracy: 0.8845\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1641 - accuracy: 0.9303 - val_loss: 0.3509 - val_accuracy: 0.8804\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.1571 - accuracy: 0.9354 - val_loss: 0.2420 - val_accuracy: 0.9015\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1525 - accuracy: 0.9362 - val_loss: 0.2823 - val_accuracy: 0.8893\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.1435 - accuracy: 0.9411 - val_loss: 0.2210 - val_accuracy: 0.9051\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1424 - accuracy: 0.9400 - val_loss: 0.2439 - val_accuracy: 0.8877\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.1324 - accuracy: 0.9452 - val_loss: 0.2632 - val_accuracy: 0.8833\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1240 - accuracy: 0.9487 - val_loss: 0.2194 - val_accuracy: 0.8930\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.1106 - accuracy: 0.9550 - val_loss: 0.1888 - val_accuracy: 0.9291\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.1092 - accuracy: 0.9566 - val_loss: 0.1687 - val_accuracy: 0.9303\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0975 - accuracy: 0.9610 - val_loss: 0.1706 - val_accuracy: 0.9278\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0927 - accuracy: 0.9637 - val_loss: 0.1878 - val_accuracy: 0.9347\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0863 - accuracy: 0.9649 - val_loss: 0.2378 - val_accuracy: 0.9193\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0699 - accuracy: 0.9715 - val_loss: 0.2640 - val_accuracy: 0.9153\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0740 - accuracy: 0.9717 - val_loss: 0.3239 - val_accuracy: 0.9035\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0613 - accuracy: 0.9756 - val_loss: 0.2714 - val_accuracy: 0.9283\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.1954 - val_accuracy: 0.9339\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0528 - accuracy: 0.9796 - val_loss: 0.3164 - val_accuracy: 0.9031\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0526 - accuracy: 0.9804 - val_loss: 0.2295 - val_accuracy: 0.9218\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0444 - accuracy: 0.9837 - val_loss: 0.3347 - val_accuracy: 0.9201\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0431 - accuracy: 0.9817 - val_loss: 0.2162 - val_accuracy: 0.9331\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0489 - accuracy: 0.9820 - val_loss: 0.2855 - val_accuracy: 0.9210\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0274 - accuracy: 0.9892 - val_loss: 0.3199 - val_accuracy: 0.9214\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.2200 - val_accuracy: 0.9355\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0365 - accuracy: 0.9872 - val_loss: 0.2800 - val_accuracy: 0.9331\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.4349 - val_accuracy: 0.9274\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0424 - accuracy: 0.9846 - val_loss: 0.3605 - val_accuracy: 0.9254\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.2884 - val_accuracy: 0.9153\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.3207 - val_accuracy: 0.9287\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0254 - accuracy: 0.9903 - val_loss: 0.2538 - val_accuracy: 0.9360\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.3245 - val_accuracy: 0.9222\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.2663 - val_accuracy: 0.9266\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.2316 - val_accuracy: 0.9372\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.5876 - val_accuracy: 0.8776\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.3013 - val_accuracy: 0.9189\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0231 - accuracy: 0.9908 - val_loss: 0.2589 - val_accuracy: 0.9295\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.2929 - val_accuracy: 0.9283\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 46s 147ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.5879 - val_accuracy: 0.9161\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.3276 - val_accuracy: 0.9311\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 0.2752 - val_accuracy: 0.9266\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.4015 - val_accuracy: 0.9226\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.4184 - val_accuracy: 0.9035\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.3493 - val_accuracy: 0.9283\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.4029 - val_accuracy: 0.9226\n",
      "97/97 - 5s - loss: 0.4274 - accuracy: 0.9251 - 5s/epoch - 47ms/step\n",
      "\n",
      "Test accuracy: 0.9250972867012024\n",
      "97/97 [==============================] - 5s 39ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.96      0.94      0.95      2208\n",
      "    landslide       0.85      0.90      0.87       876\n",
      "\n",
      "     accuracy                           0.93      3084\n",
      "    macro avg       0.90      0.92      0.91      3084\n",
      " weighted avg       0.93      0.93      0.93      3084\n",
      "\n",
      "Accuracy: 0.5864093324652909\n",
      "Precision: 0.8961187214611872\n",
      "Recall: 0.8961187214611872\n",
      "F1 Score: 0.8961187214611872\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用DenseNet121）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用VGG16）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = VGG16(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e57b038-7e01-441e-9533-4dbb015a4922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "309/309 [==============================] - 61s 161ms/step - loss: 0.5835 - accuracy: 0.8935 - val_loss: 0.2597 - val_accuracy: 0.8837\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 48s 156ms/step - loss: 0.2075 - accuracy: 0.9109 - val_loss: 0.1738 - val_accuracy: 0.9274\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1885 - accuracy: 0.9209 - val_loss: 0.4783 - val_accuracy: 0.8435\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1862 - accuracy: 0.9213 - val_loss: 0.8120 - val_accuracy: 0.8034\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1723 - accuracy: 0.9286 - val_loss: 0.2263 - val_accuracy: 0.9177\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1664 - accuracy: 0.9290 - val_loss: 0.2200 - val_accuracy: 0.9137\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.1574 - accuracy: 0.9368 - val_loss: 0.2532 - val_accuracy: 0.9185\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.1635 - accuracy: 0.9316 - val_loss: 0.2125 - val_accuracy: 0.9112\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.1449 - accuracy: 0.9411 - val_loss: 0.4550 - val_accuracy: 0.8058\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.1401 - accuracy: 0.9417 - val_loss: 0.3436 - val_accuracy: 0.8877\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.1440 - accuracy: 0.9422 - val_loss: 0.1844 - val_accuracy: 0.9214\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.1275 - accuracy: 0.9482 - val_loss: 0.1756 - val_accuracy: 0.9283\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 46s 151ms/step - loss: 0.1253 - accuracy: 0.9478 - val_loss: 0.1583 - val_accuracy: 0.9384\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1188 - accuracy: 0.9510 - val_loss: 0.3870 - val_accuracy: 0.8285\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1013 - accuracy: 0.9567 - val_loss: 0.1869 - val_accuracy: 0.9291\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0969 - accuracy: 0.9604 - val_loss: 0.3493 - val_accuracy: 0.8464\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0896 - accuracy: 0.9654 - val_loss: 0.2918 - val_accuracy: 0.8910\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0901 - accuracy: 0.9633 - val_loss: 0.2190 - val_accuracy: 0.9230\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0693 - accuracy: 0.9727 - val_loss: 0.2646 - val_accuracy: 0.8970\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0768 - accuracy: 0.9687 - val_loss: 0.2452 - val_accuracy: 0.9266\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0679 - accuracy: 0.9736 - val_loss: 0.3908 - val_accuracy: 0.8772\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0654 - accuracy: 0.9768 - val_loss: 0.2581 - val_accuracy: 0.9291\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 0.2389 - val_accuracy: 0.9173\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0457 - accuracy: 0.9834 - val_loss: 0.2341 - val_accuracy: 0.9157\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 0.3647 - val_accuracy: 0.9064\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 46s 147ms/step - loss: 0.0527 - accuracy: 0.9795 - val_loss: 0.2669 - val_accuracy: 0.9218\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.3185 - val_accuracy: 0.9230\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0451 - accuracy: 0.9840 - val_loss: 0.3293 - val_accuracy: 0.9210\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.2374 - val_accuracy: 0.9303\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0300 - accuracy: 0.9894 - val_loss: 0.2561 - val_accuracy: 0.9210\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.3335 - val_accuracy: 0.9226\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0371 - accuracy: 0.9871 - val_loss: 0.2808 - val_accuracy: 0.9335\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.2808 - val_accuracy: 0.9197\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0254 - accuracy: 0.9901 - val_loss: 0.3067 - val_accuracy: 0.9319\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.3214 - val_accuracy: 0.9299\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0296 - accuracy: 0.9891 - val_loss: 0.2768 - val_accuracy: 0.9226\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.0251 - accuracy: 0.9904 - val_loss: 0.3272 - val_accuracy: 0.9323\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.5540 - val_accuracy: 0.9023\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0208 - accuracy: 0.9925 - val_loss: 0.3342 - val_accuracy: 0.9210\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.2773 - val_accuracy: 0.9226\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.3968 - val_accuracy: 0.9116\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.6816 - val_accuracy: 0.8991\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 0.3801 - val_accuracy: 0.9015\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0210 - accuracy: 0.9915 - val_loss: 0.3298 - val_accuracy: 0.9230\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.5093 - val_accuracy: 0.9072\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 0.3463 - val_accuracy: 0.9295\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 46s 147ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.3609 - val_accuracy: 0.9274\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.3372 - val_accuracy: 0.9347\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0152 - accuracy: 0.9937 - val_loss: 0.3087 - val_accuracy: 0.9197\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 0.3779 - val_accuracy: 0.9311\n",
      "97/97 - 4s - loss: 0.3855 - accuracy: 0.9280 - 4s/epoch - 41ms/step\n",
      "\n",
      "Test accuracy: 0.9280155897140503\n",
      "97/97 [==============================] - 5s 39ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.96      0.94      0.95      2208\n",
      "    landslide       0.86      0.89      0.88       876\n",
      "\n",
      "     accuracy                           0.93      3084\n",
      "    macro avg       0.91      0.92      0.91      3084\n",
      " weighted avg       0.93      0.93      0.93      3084\n",
      "\n",
      "Accuracy: 0.5885100455722266\n",
      "Precision: 0.8926940639269406\n",
      "Recall: 0.8926940639269406\n",
      "F1 Score: 0.8926940639269406\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用DenseNet121）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用VGG16）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = VGG16(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9caa243c-a5d4-4ed4-80d0-944fa31fbeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 61s 151ms/step - loss: 0.2792 - accuracy: 0.8806 - val_loss: 0.5926 - val_accuracy: 0.8472\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 44s 143ms/step - loss: 0.2313 - accuracy: 0.9031 - val_loss: 30.5819 - val_accuracy: 0.7049\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.2200 - accuracy: 0.9049 - val_loss: 0.2928 - val_accuracy: 0.8577\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.2011 - accuracy: 0.9156 - val_loss: 0.1948 - val_accuracy: 0.9161\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1949 - accuracy: 0.9183 - val_loss: 0.2347 - val_accuracy: 0.9161\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1850 - accuracy: 0.9232 - val_loss: 0.3850 - val_accuracy: 0.8642\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1696 - accuracy: 0.9280 - val_loss: 0.2246 - val_accuracy: 0.9076\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1682 - accuracy: 0.9296 - val_loss: 0.3902 - val_accuracy: 0.8691\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.1636 - accuracy: 0.9330 - val_loss: 0.3882 - val_accuracy: 0.8711\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1448 - accuracy: 0.9411 - val_loss: 0.1978 - val_accuracy: 0.9133\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1342 - accuracy: 0.9460 - val_loss: 0.3433 - val_accuracy: 0.8780\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1399 - accuracy: 0.9436 - val_loss: 0.2040 - val_accuracy: 0.9177\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.1276 - accuracy: 0.9505 - val_loss: 0.2289 - val_accuracy: 0.9092\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.1243 - accuracy: 0.9514 - val_loss: 0.2003 - val_accuracy: 0.9185\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.1113 - accuracy: 0.9552 - val_loss: 0.4112 - val_accuracy: 0.8662\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.1082 - accuracy: 0.9554 - val_loss: 0.4333 - val_accuracy: 0.8439\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 44s 144ms/step - loss: 0.0876 - accuracy: 0.9679 - val_loss: 0.2830 - val_accuracy: 0.8881\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0887 - accuracy: 0.9665 - val_loss: 0.2235 - val_accuracy: 0.9226\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0701 - accuracy: 0.9730 - val_loss: 0.3917 - val_accuracy: 0.8723\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.2797 - val_accuracy: 0.9193\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 44s 144ms/step - loss: 0.0490 - accuracy: 0.9838 - val_loss: 0.6880 - val_accuracy: 0.8597\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 45s 144ms/step - loss: 0.0511 - accuracy: 0.9791 - val_loss: 0.2988 - val_accuracy: 0.9023\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.4964 - val_accuracy: 0.8869\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 0.4596 - val_accuracy: 0.8756\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.3465 - val_accuracy: 0.9007\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 0.2576 - val_accuracy: 0.9206\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 42s 135ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.4026 - val_accuracy: 0.9064\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.4113 - val_accuracy: 0.9145\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 44s 142ms/step - loss: 0.0426 - accuracy: 0.9851 - val_loss: 0.7907 - val_accuracy: 0.8492\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.3501 - val_accuracy: 0.9072\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.2820 - val_accuracy: 0.9226\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.3674 - val_accuracy: 0.9173\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0804 - accuracy: 0.9693 - val_loss: 0.3204 - val_accuracy: 0.9080\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.2916 - val_accuracy: 0.9181\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.3324 - val_accuracy: 0.9230\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.3743 - val_accuracy: 0.9128\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.3179 - val_accuracy: 0.9206\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.3426 - val_accuracy: 0.9153\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.5768 - val_accuracy: 0.8772\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.3487 - val_accuracy: 0.9181\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.5207 - val_accuracy: 0.9047\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 43s 141ms/step - loss: 0.0187 - accuracy: 0.9929 - val_loss: 0.4214 - val_accuracy: 0.8983\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.4046 - val_accuracy: 0.9056\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.5620 - val_accuracy: 0.8760\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.5620 - val_accuracy: 0.9003\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 43s 140ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.5394 - val_accuracy: 0.8910\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 44s 141ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.4831 - val_accuracy: 0.8877\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 42s 136ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.5549 - val_accuracy: 0.9084\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 43s 139ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.8707 - val_accuracy: 0.8642\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 43s 138ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.3725 - val_accuracy: 0.9193\n",
      "97/97 - 3s - loss: 0.3624 - accuracy: 0.9092 - 3s/epoch - 28ms/step\n",
      "\n",
      "Test accuracy: 0.9092088341712952\n",
      "97/97 [==============================] - 4s 23ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.93      0.95      0.94      2208\n",
      "    landslide       0.86      0.81      0.84       876\n",
      "\n",
      "     accuracy                           0.91      3084\n",
      "    macro avg       0.89      0.88      0.89      3084\n",
      " weighted avg       0.91      0.91      0.91      3084\n",
      "\n",
      "Accuracy: 0.6005541340519917\n",
      "Precision: 0.8105022831050228\n",
      "Recall: 0.8105022831050228\n",
      "F1 Score: 0.8105022831050227\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用InceptionV3）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用MobileNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa52756-c352-47ce-86d7-c700b045f11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "309/309 [==============================] - 62s 161ms/step - loss: 0.4167 - accuracy: 0.8924 - val_loss: 0.6544 - val_accuracy: 0.7868\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 48s 155ms/step - loss: 0.2151 - accuracy: 0.9101 - val_loss: 0.1937 - val_accuracy: 0.9149\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 45s 144ms/step - loss: 0.1951 - accuracy: 0.9199 - val_loss: 0.4133 - val_accuracy: 0.8610\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.1886 - accuracy: 0.9195 - val_loss: 0.2489 - val_accuracy: 0.8954\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1837 - accuracy: 0.9229 - val_loss: 0.4556 - val_accuracy: 0.8168\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1712 - accuracy: 0.9302 - val_loss: 0.2466 - val_accuracy: 0.9035\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1634 - accuracy: 0.9304 - val_loss: 0.1922 - val_accuracy: 0.9096\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.1572 - accuracy: 0.9342 - val_loss: 0.2660 - val_accuracy: 0.8995\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.1550 - accuracy: 0.9361 - val_loss: 0.3598 - val_accuracy: 0.8776\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 45s 144ms/step - loss: 0.1466 - accuracy: 0.9397 - val_loss: 0.2179 - val_accuracy: 0.9072\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1436 - accuracy: 0.9392 - val_loss: 0.3031 - val_accuracy: 0.8650\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1301 - accuracy: 0.9444 - val_loss: 0.1647 - val_accuracy: 0.9364\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 45s 144ms/step - loss: 0.1284 - accuracy: 0.9460 - val_loss: 0.4440 - val_accuracy: 0.8719\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.1181 - accuracy: 0.9528 - val_loss: 0.3906 - val_accuracy: 0.8995\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.1139 - accuracy: 0.9526 - val_loss: 0.2897 - val_accuracy: 0.9270\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 45s 144ms/step - loss: 0.0960 - accuracy: 0.9635 - val_loss: 0.2371 - val_accuracy: 0.9177\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0900 - accuracy: 0.9644 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0977 - accuracy: 0.9602 - val_loss: 0.2158 - val_accuracy: 0.9173\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 45s 144ms/step - loss: 0.0829 - accuracy: 0.9676 - val_loss: 0.2748 - val_accuracy: 0.9047\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0709 - accuracy: 0.9713 - val_loss: 0.2755 - val_accuracy: 0.9096\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 45s 146ms/step - loss: 0.0735 - accuracy: 0.9708 - val_loss: 0.2096 - val_accuracy: 0.9307\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 47s 154ms/step - loss: 0.0568 - accuracy: 0.9790 - val_loss: 0.3827 - val_accuracy: 0.9035\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0629 - accuracy: 0.9766 - val_loss: 0.2558 - val_accuracy: 0.9291\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0493 - accuracy: 0.9809 - val_loss: 0.3331 - val_accuracy: 0.8991\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0380 - accuracy: 0.9866 - val_loss: 0.3569 - val_accuracy: 0.9027\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 0.3214 - val_accuracy: 0.9210\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0453 - accuracy: 0.9821 - val_loss: 0.2503 - val_accuracy: 0.9238\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 0.2935 - val_accuracy: 0.9351\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0385 - accuracy: 0.9871 - val_loss: 0.3174 - val_accuracy: 0.9060\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0389 - accuracy: 0.9849 - val_loss: 0.2484 - val_accuracy: 0.9351\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 46s 149ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 0.4043 - val_accuracy: 0.9064\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.7220 - val_accuracy: 0.8387\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0337 - accuracy: 0.9877 - val_loss: 0.2520 - val_accuracy: 0.9327\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0241 - accuracy: 0.9909 - val_loss: 0.4585 - val_accuracy: 0.9080\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.3035 - val_accuracy: 0.9254\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 47s 152ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.3423 - val_accuracy: 0.9214\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.3384 - val_accuracy: 0.9116\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.3260 - val_accuracy: 0.9343\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.3391 - val_accuracy: 0.9201\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.3874 - val_accuracy: 0.9084\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 46s 150ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.5091 - val_accuracy: 0.9161\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.2899 - val_accuracy: 0.9258\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.4011 - val_accuracy: 0.9262\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 47s 151ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.3536 - val_accuracy: 0.9133\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 45s 147ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.5563 - val_accuracy: 0.8930\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 45s 145ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.4122 - val_accuracy: 0.9116\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.3286 - val_accuracy: 0.9274\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 46s 147ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.3460 - val_accuracy: 0.9278\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 48s 154ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.4169 - val_accuracy: 0.8934\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 46s 148ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.4043 - val_accuracy: 0.9303\n",
      "97/97 - 4s - loss: 0.4482 - accuracy: 0.9173 - 4s/epoch - 41ms/step\n",
      "\n",
      "Test accuracy: 0.9173151850700378\n",
      "97/97 [==============================] - 6s 39ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.93      0.96      0.94      2208\n",
      "    landslide       0.89      0.81      0.85       876\n",
      "\n",
      "     accuracy                           0.92      3084\n",
      "    macro avg       0.91      0.89      0.90      3084\n",
      " weighted avg       0.92      0.92      0.92      3084\n",
      "\n",
      "Accuracy: 0.6040553225635513\n",
      "Precision: 0.8105022831050228\n",
      "Recall: 0.8105022831050228\n",
      "F1 Score: 0.8105022831050227\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用DenseNet121）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用VGG16）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = VGG16(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848a626a-b1c5-443e-aaa4-d3d564cf0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 02:40:36.995110: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-20 02:41:13.391603: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-20 02:41:13.758914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46662 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:71:01.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 02:41:29.105987: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-20 02:41:29.822853: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-20 02:41:29.822872: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-20 02:41:29.822916: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-20 02:41:30.605609: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234/1234 [==============================] - 81s 60ms/step - loss: 0.9418 - accuracy: 0.7464 - val_loss: 0.6020 - val_accuracy: 0.7175\n",
      "Epoch 2/50\n",
      "1234/1234 [==============================] - 70s 57ms/step - loss: 0.5969 - accuracy: 0.7198 - val_loss: 0.5988 - val_accuracy: 0.7175\n",
      "Epoch 3/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.6013 - accuracy: 0.7190 - val_loss: 0.5956 - val_accuracy: 0.7175\n",
      "Epoch 4/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5953 - accuracy: 0.7198 - val_loss: 0.5956 - val_accuracy: 0.7175\n",
      "Epoch 5/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5951 - accuracy: 0.7198 - val_loss: 0.5964 - val_accuracy: 0.7175\n",
      "Epoch 6/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5946 - accuracy: 0.7198 - val_loss: 0.5955 - val_accuracy: 0.7175\n",
      "Epoch 7/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5971 - accuracy: 0.7196 - val_loss: 0.5962 - val_accuracy: 0.7175\n",
      "Epoch 8/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5949 - accuracy: 0.7198 - val_loss: 0.5957 - val_accuracy: 0.7175\n",
      "Epoch 9/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5944 - accuracy: 0.7198 - val_loss: 0.5957 - val_accuracy: 0.7175\n",
      "Epoch 10/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5949 - accuracy: 0.7198 - val_loss: 0.5958 - val_accuracy: 0.7175\n",
      "Epoch 11/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5955 - accuracy: 0.7198 - val_loss: 0.5969 - val_accuracy: 0.7175\n",
      "Epoch 12/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5949 - accuracy: 0.7192 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 13/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5950 - accuracy: 0.7194 - val_loss: 0.5965 - val_accuracy: 0.7175\n",
      "Epoch 14/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5947 - accuracy: 0.7196 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 15/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5950 - accuracy: 0.7198 - val_loss: 0.5959 - val_accuracy: 0.7175\n",
      "Epoch 16/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5940 - accuracy: 0.7198 - val_loss: 0.5976 - val_accuracy: 0.7175\n",
      "Epoch 17/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5951 - accuracy: 0.7198 - val_loss: 0.5963 - val_accuracy: 0.7175\n",
      "Epoch 18/50\n",
      "1234/1234 [==============================] - 70s 57ms/step - loss: 0.5944 - accuracy: 0.7198 - val_loss: 0.5954 - val_accuracy: 0.7175\n",
      "Epoch 19/50\n",
      "1234/1234 [==============================] - 70s 56ms/step - loss: 0.5942 - accuracy: 0.7198 - val_loss: 0.5966 - val_accuracy: 0.7175\n",
      "Epoch 20/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5941 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 21/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5966 - accuracy: 0.7198 - val_loss: 0.5955 - val_accuracy: 0.7175\n",
      "Epoch 22/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5938 - accuracy: 0.7198 - val_loss: 0.5964 - val_accuracy: 0.7175\n",
      "Epoch 23/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5936 - accuracy: 0.7198 - val_loss: 0.5957 - val_accuracy: 0.7175\n",
      "Epoch 24/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5939 - accuracy: 0.7198 - val_loss: 0.5972 - val_accuracy: 0.7175\n",
      "Epoch 25/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5940 - accuracy: 0.7198 - val_loss: 0.5964 - val_accuracy: 0.7175\n",
      "Epoch 26/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5934 - accuracy: 0.7198 - val_loss: 0.5967 - val_accuracy: 0.7175\n",
      "Epoch 27/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5942 - accuracy: 0.7198 - val_loss: 0.5956 - val_accuracy: 0.7175\n",
      "Epoch 28/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5937 - accuracy: 0.7198 - val_loss: 0.5959 - val_accuracy: 0.7175\n",
      "Epoch 29/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5938 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 30/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5938 - accuracy: 0.7198 - val_loss: 0.5976 - val_accuracy: 0.7175\n",
      "Epoch 31/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5936 - accuracy: 0.7198 - val_loss: 0.5954 - val_accuracy: 0.7175\n",
      "Epoch 32/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5940 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 33/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5956 - val_accuracy: 0.7175\n",
      "Epoch 34/50\n",
      "1234/1234 [==============================] - 70s 56ms/step - loss: 0.5938 - accuracy: 0.7198 - val_loss: 0.5989 - val_accuracy: 0.7175\n",
      "Epoch 35/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 36/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5938 - accuracy: 0.7198 - val_loss: 0.5959 - val_accuracy: 0.7175\n",
      "Epoch 37/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5938 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 38/50\n",
      "1234/1234 [==============================] - 68s 56ms/step - loss: 0.5936 - accuracy: 0.7198 - val_loss: 0.5954 - val_accuracy: 0.7175\n",
      "Epoch 39/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5937 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 40/50\n",
      "1234/1234 [==============================] - 68s 56ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5959 - val_accuracy: 0.7175\n",
      "Epoch 41/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5960 - val_accuracy: 0.7175\n",
      "Epoch 42/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5934 - accuracy: 0.7198 - val_loss: 0.5958 - val_accuracy: 0.7175\n",
      "Epoch 43/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5954 - val_accuracy: 0.7175\n",
      "Epoch 44/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5936 - accuracy: 0.7198 - val_loss: 0.5954 - val_accuracy: 0.7175\n",
      "Epoch 45/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5957 - val_accuracy: 0.7175\n",
      "Epoch 46/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5953 - val_accuracy: 0.7175\n",
      "Epoch 47/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5934 - accuracy: 0.7198 - val_loss: 0.5956 - val_accuracy: 0.7175\n",
      "Epoch 48/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5969 - val_accuracy: 0.7175\n",
      "Epoch 49/50\n",
      "1234/1234 [==============================] - 69s 56ms/step - loss: 0.5934 - accuracy: 0.7198 - val_loss: 0.5960 - val_accuracy: 0.7175\n",
      "Epoch 50/50\n",
      "1234/1234 [==============================] - 68s 55ms/step - loss: 0.5935 - accuracy: 0.7198 - val_loss: 0.5954 - val_accuracy: 0.7175\n",
      "97/97 - 6s - loss: 0.5968 - accuracy: 0.7160 - 6s/epoch - 61ms/step\n",
      "\n",
      "Test accuracy: 0.7159532904624939\n",
      "97/97 [==============================] - 4s 34ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.72      1.00      0.83      2208\n",
      "    landslide       0.00      0.00      0.00       876\n",
      "\n",
      "     accuracy                           0.72      3084\n",
      "    macro avg       0.36      0.50      0.42      3084\n",
      " weighted avg       0.51      0.72      0.60      3084\n",
      "\n",
      "Accuracy: 0.7159533073929961\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_1206/799019489.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score = 2 * precision * recall / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 8\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用VGG19）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = VGG19(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用MobileNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b379ec50-80f8-4eb6-8cbf-15a36807c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 21:48:15.968806: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 21:48:52.508397: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 21:48:52.970311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46662 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:71:01.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 21:49:22.225603: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-19 21:49:22.958132: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-19 21:49:22.958157: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-19 21:49:22.958221: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-19 21:49:24.126855: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 63s 146ms/step - loss: 0.2906 - accuracy: 0.8778 - val_loss: 0.4110 - val_accuracy: 0.8557\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 41s 133ms/step - loss: 0.2326 - accuracy: 0.9019 - val_loss: 0.2287 - val_accuracy: 0.8970\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 41s 134ms/step - loss: 0.2164 - accuracy: 0.9095 - val_loss: 0.2298 - val_accuracy: 0.9189\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1872 - accuracy: 0.9199 - val_loss: 0.4527 - val_accuracy: 0.7900\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 39s 125ms/step - loss: 0.1812 - accuracy: 0.9252 - val_loss: 0.2151 - val_accuracy: 0.9181\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 40s 128ms/step - loss: 0.1724 - accuracy: 0.9307 - val_loss: 0.2101 - val_accuracy: 0.9043\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 40s 128ms/step - loss: 0.1683 - accuracy: 0.9315 - val_loss: 0.3464 - val_accuracy: 0.8820\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.1547 - accuracy: 0.9345 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1395 - accuracy: 0.9432 - val_loss: 0.2152 - val_accuracy: 0.9100\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 41s 132ms/step - loss: 0.1347 - accuracy: 0.9446 - val_loss: 0.2765 - val_accuracy: 0.8954\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.1375 - accuracy: 0.9437 - val_loss: 0.2062 - val_accuracy: 0.9193\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.1156 - accuracy: 0.9544 - val_loss: 0.2246 - val_accuracy: 0.9206\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.1002 - accuracy: 0.9593 - val_loss: 0.5059 - val_accuracy: 0.8435\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.0913 - accuracy: 0.9649 - val_loss: 0.4192 - val_accuracy: 0.8679\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 39s 128ms/step - loss: 0.0810 - accuracy: 0.9681 - val_loss: 0.3176 - val_accuracy: 0.9003\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 39s 128ms/step - loss: 0.0779 - accuracy: 0.9707 - val_loss: 0.2366 - val_accuracy: 0.9169\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 40s 130ms/step - loss: 0.0611 - accuracy: 0.9768 - val_loss: 0.4563 - val_accuracy: 0.8747\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 0.3922 - val_accuracy: 0.8549\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 40s 129ms/step - loss: 0.0547 - accuracy: 0.9793 - val_loss: 0.3038 - val_accuracy: 0.9161\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 39s 126ms/step - loss: 0.0431 - accuracy: 0.9838 - val_loss: 0.3724 - val_accuracy: 0.9145\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 39s 128ms/step - loss: 0.0475 - accuracy: 0.9820 - val_loss: 0.3398 - val_accuracy: 0.9112\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 0.5930 - val_accuracy: 0.8577\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 41s 131ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.2584 - val_accuracy: 0.9072\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 40s 131ms/step - loss: 0.0345 - accuracy: 0.9880 - val_loss: 0.2873 - val_accuracy: 0.9222\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 41s 131ms/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.3490 - val_accuracy: 0.9116\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.3903 - val_accuracy: 0.9072\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 39s 128ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.3195 - val_accuracy: 0.9124\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 39s 126ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.2595 - val_accuracy: 0.9197\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.0262 - accuracy: 0.9902 - val_loss: 0.3531 - val_accuracy: 0.9039\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 40s 128ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.9474 - val_accuracy: 0.8148\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.3079 - val_accuracy: 0.9189\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 1.0287 - val_accuracy: 0.8079\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 38s 123ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.4222 - val_accuracy: 0.9084\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 39s 125ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.2847 - val_accuracy: 0.9258\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 38s 123ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.3883 - val_accuracy: 0.9116\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 39s 125ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.4872 - val_accuracy: 0.9133\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 39s 126ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.5905 - val_accuracy: 0.8804\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.3893 - val_accuracy: 0.9218\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.3654 - val_accuracy: 0.9068\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 38s 122ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.3522 - val_accuracy: 0.9165\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.4511 - val_accuracy: 0.9027\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 39s 126ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.4150 - val_accuracy: 0.9222\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 1.1763 - val_accuracy: 0.7860\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.3777 - val_accuracy: 0.8938\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 38s 123ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.5152 - val_accuracy: 0.9222\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 3375.8618 - val_accuracy: 0.2825\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 39s 125ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 38s 124ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.3797 - val_accuracy: 0.9128\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 39s 127ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 0.4446 - val_accuracy: 0.9177\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 39s 125ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.3893 - val_accuracy: 0.9133\n",
      "97/97 - 4s - loss: 0.3937 - accuracy: 0.9128 - 4s/epoch - 43ms/step\n",
      "\n",
      "Test accuracy: 0.9127756357192993\n",
      "97/97 [==============================] - 6s 34ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.92      0.96      0.94      2208\n",
      "    landslide       0.88      0.80      0.84       876\n",
      "\n",
      "     accuracy                           0.91      3084\n",
      "    macro avg       0.90      0.88      0.89      3084\n",
      " weighted avg       0.91      0.91      0.91      3084\n",
      "\n",
      "Accuracy: 0.6051757028872504\n",
      "Precision: 0.797945205479452\n",
      "Recall: 0.797945205479452\n",
      "F1 Score: 0.797945205479452\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3, DenseNet121\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用InceptionV3）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用DenseNet121）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b5e443-35a2-4bfb-a3a1-d29eb26bceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 91s 266ms/step - loss: 0.2561 - accuracy: 0.8939 - val_loss: 1.5745 - val_accuracy: 0.6437\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.2111 - accuracy: 0.9120 - val_loss: 3.2450 - val_accuracy: 0.4422\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 78s 254ms/step - loss: 0.1837 - accuracy: 0.9226 - val_loss: 2.7858 - val_accuracy: 0.5351\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.1681 - accuracy: 0.9304 - val_loss: 2.3337 - val_accuracy: 0.5882\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.1517 - accuracy: 0.9397 - val_loss: 5.2514 - val_accuracy: 0.3470\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 77s 251ms/step - loss: 0.1378 - accuracy: 0.9443 - val_loss: 0.6163 - val_accuracy: 0.8087\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 78s 254ms/step - loss: 0.1272 - accuracy: 0.9511 - val_loss: 6.2211 - val_accuracy: 0.4179\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 78s 252ms/step - loss: 0.1160 - accuracy: 0.9514 - val_loss: 0.7446 - val_accuracy: 0.7884\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.1106 - accuracy: 0.9585 - val_loss: 7.3281 - val_accuracy: 0.2833\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 78s 254ms/step - loss: 0.1002 - accuracy: 0.9594 - val_loss: 7.3377 - val_accuracy: 0.3571\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 78s 254ms/step - loss: 0.0800 - accuracy: 0.9687 - val_loss: 10.1222 - val_accuracy: 0.3445\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.0784 - accuracy: 0.9680 - val_loss: 1.3704 - val_accuracy: 0.7126\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.0723 - accuracy: 0.9738 - val_loss: 0.5239 - val_accuracy: 0.8731\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 78s 252ms/step - loss: 0.0669 - accuracy: 0.9758 - val_loss: 3.8727 - val_accuracy: 0.4905\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 78s 251ms/step - loss: 0.0536 - accuracy: 0.9811 - val_loss: 1.5615 - val_accuracy: 0.7426\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 78s 251ms/step - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.7551 - val_accuracy: 0.8492\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 78s 252ms/step - loss: 0.0555 - accuracy: 0.9786 - val_loss: 3.0239 - val_accuracy: 0.6105\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 78s 254ms/step - loss: 0.0533 - accuracy: 0.9803 - val_loss: 4.4429 - val_accuracy: 0.4293\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 78s 253ms/step - loss: 0.0426 - accuracy: 0.9845 - val_loss: 1.3671 - val_accuracy: 0.8160\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 78s 252ms/step - loss: 0.0379 - accuracy: 0.9853 - val_loss: 4.4840 - val_accuracy: 0.4937\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 78s 251ms/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 5.9709 - val_accuracy: 0.3883\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 77s 249ms/step - loss: 0.0425 - accuracy: 0.9856 - val_loss: 3.3306 - val_accuracy: 0.5829\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 77s 249ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.8728 - val_accuracy: 0.8119\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 76s 247ms/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 1.2531 - val_accuracy: 0.8808\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.7541 - val_accuracy: 0.8877\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 76s 247ms/step - loss: 0.0587 - accuracy: 0.9781 - val_loss: 2.0771 - val_accuracy: 0.6194\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 77s 248ms/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.7946 - val_accuracy: 0.8747\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 76s 246ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.6918 - val_accuracy: 0.8885\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.5513 - val_accuracy: 0.8849\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.6165 - val_accuracy: 0.8638\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.9058 - val_accuracy: 0.8593\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.6325 - val_accuracy: 0.8829\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 75s 241ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.7847 - val_accuracy: 0.8897\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0217 - accuracy: 0.9915 - val_loss: 1.1028 - val_accuracy: 0.8127\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 75s 243ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.4525 - val_accuracy: 0.9047\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0167 - accuracy: 0.9936 - val_loss: 1.4842 - val_accuracy: 0.8221\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 74s 241ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 1.0437 - val_accuracy: 0.8488\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 1.2672 - val_accuracy: 0.8050\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 2.9361 - val_accuracy: 0.6259\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 74s 240ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.5551 - val_accuracy: 0.9133\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.3513 - val_accuracy: 0.8918\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.5136 - val_accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 74s 241ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 1.8025 - val_accuracy: 0.7434\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 1.0275 - val_accuracy: 0.8788\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 74s 240ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 5.7764 - val_accuracy: 0.4759\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 75s 244ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.8653 - val_accuracy: 0.8545\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 74s 241ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 1.5737 - val_accuracy: 0.7762\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 74s 239ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.7643 - val_accuracy: 0.8618\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 76s 245ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.8410 - val_accuracy: 0.8658\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 75s 242ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.6430 - val_accuracy: 0.9112\n",
      "97/97 - 3s - loss: 0.5479 - accuracy: 0.9186 - 3s/epoch - 35ms/step\n",
      "\n",
      "Test accuracy: 0.9186121821403503\n",
      "97/97 [==============================] - 4s 31ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.96      0.93      0.94      2208\n",
      "    landslide       0.83      0.89      0.86       876\n",
      "\n",
      "     accuracy                           0.92      3084\n",
      "    macro avg       0.89      0.91      0.90      3084\n",
      " weighted avg       0.92      0.92      0.92      3084\n",
      "\n",
      "Accuracy: 0.5844486668988176\n",
      "Precision: 0.8926940639269406\n",
      "Recall: 0.8926940639269406\n",
      "F1 Score: 0.8926940639269406\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNetV2）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用Xception）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = Xception(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8005b5d-839f-4bd8-bb39-d6c7d139044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 119s 7us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234545216/234545216 [==============================] - 930s 4us/step\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 96s 249ms/step - loss: 0.2349 - accuracy: 0.9024 - val_loss: 0.2595 - val_accuracy: 0.9039\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.1666 - accuracy: 0.9358 - val_loss: 0.4231 - val_accuracy: 0.8091\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 70s 228ms/step - loss: 0.1419 - accuracy: 0.9431 - val_loss: 0.1871 - val_accuracy: 0.9238\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.1157 - accuracy: 0.9516 - val_loss: 0.2318 - val_accuracy: 0.9218\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 72s 234ms/step - loss: 0.1054 - accuracy: 0.9593 - val_loss: 0.1794 - val_accuracy: 0.9343\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0837 - accuracy: 0.9661 - val_loss: 784282905739264.0000 - val_accuracy: 0.7175\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 72s 231ms/step - loss: 0.0688 - accuracy: 0.9758 - val_loss: 0.7738 - val_accuracy: 0.8423\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 72s 232ms/step - loss: 0.0606 - accuracy: 0.9771 - val_loss: 0.2710 - val_accuracy: 0.9043\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0621 - accuracy: 0.9773 - val_loss: 0.2086 - val_accuracy: 0.9161\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0502 - accuracy: 0.9814 - val_loss: 0.4164 - val_accuracy: 0.9011\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 72s 233ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 0.5719 - val_accuracy: 0.8456\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0386 - accuracy: 0.9865 - val_loss: 0.3301 - val_accuracy: 0.8816\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0449 - accuracy: 0.9829 - val_loss: 18.1552 - val_accuracy: 0.7179\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0358 - accuracy: 0.9863 - val_loss: 3.1461 - val_accuracy: 0.7523\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.4719 - val_accuracy: 0.9287\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 6.7296 - val_accuracy: 0.7321\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 72s 232ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.4168 - val_accuracy: 0.9035\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 70s 228ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.3421 - val_accuracy: 0.9283\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 72s 233ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.2616 - val_accuracy: 0.9319\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0418 - accuracy: 0.9855 - val_loss: 0.2639 - val_accuracy: 0.9299\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.3742 - val_accuracy: 0.9270\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 71s 228ms/step - loss: 0.0224 - accuracy: 0.9920 - val_loss: 0.3193 - val_accuracy: 0.9315\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 72s 233ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.2559 - val_accuracy: 0.9218\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.3354 - val_accuracy: 0.9368\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 70s 227ms/step - loss: 0.0161 - accuracy: 0.9932 - val_loss: 0.3583 - val_accuracy: 0.9384\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 70s 228ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.3389 - val_accuracy: 0.9372\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 72s 233ms/step - loss: 0.0211 - accuracy: 0.9914 - val_loss: 0.5625 - val_accuracy: 0.9116\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.3093 - val_accuracy: 0.9388\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.3352 - val_accuracy: 0.9218\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 0.5679 - val_accuracy: 0.9084\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.4176 - val_accuracy: 0.9327\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.2918 - val_accuracy: 0.9303\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.3458 - val_accuracy: 0.9266\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.4261 - val_accuracy: 0.9161\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 70s 227ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.2954 - val_accuracy: 0.9355\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.3130 - val_accuracy: 0.9315\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 70s 228ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.4173 - val_accuracy: 0.9351\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.3621 - val_accuracy: 0.9392\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.3438 - val_accuracy: 0.9250\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 70s 227ms/step - loss: 0.0123 - accuracy: 0.9946 - val_loss: 0.3871 - val_accuracy: 0.9177\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 71s 231ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.4157 - val_accuracy: 0.9380\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 70s 228ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.3994 - val_accuracy: 0.9343\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 70s 228ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.3513 - val_accuracy: 0.9372\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.3136 - val_accuracy: 0.9364\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 72s 234ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.2820 - val_accuracy: 0.9355\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 71s 228ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.4430 - val_accuracy: 0.9149\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 71s 229ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.2746 - val_accuracy: 0.9360\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 72s 231ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.3240 - val_accuracy: 0.9254\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 71s 230ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.4411 - val_accuracy: 0.9258\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 72s 232ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.3261 - val_accuracy: 0.9278\n",
      "97/97 - 5s - loss: 0.2947 - accuracy: 0.9329 - 5s/epoch - 56ms/step\n",
      "\n",
      "Test accuracy: 0.9328793883323669\n",
      "97/97 [==============================] - 8s 53ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.96      0.94      0.95      2208\n",
      "    landslide       0.87      0.90      0.88       876\n",
      "\n",
      "     accuracy                           0.93      3084\n",
      "    macro avg       0.91      0.92      0.92      3084\n",
      " weighted avg       0.93      0.93      0.93      3084\n",
      "\n",
      "Accuracy: 0.5880899029508395\n",
      "Precision: 0.9029680365296804\n",
      "Recall: 0.9029680365296804\n",
      "F1 Score: 0.9029680365296804\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet152V2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用EfficientNetB0）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用ResNet152V2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = ResNet152V2(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ece6b9-3060-47e4-be58-b995c915f261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "19993432/19993432 [==============================] - 2s 0us/step\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 123s 335ms/step - loss: 0.2247 - accuracy: 0.9071 - val_loss: 43.0701 - val_accuracy: 0.7175\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 100s 323ms/step - loss: 0.1625 - accuracy: 0.9332 - val_loss: 10.1262 - val_accuracy: 0.7061\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 101s 327ms/step - loss: 0.1442 - accuracy: 0.9411 - val_loss: 3.9546 - val_accuracy: 0.8468\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 100s 323ms/step - loss: 0.1119 - accuracy: 0.9562 - val_loss: 8.4028 - val_accuracy: 0.8537\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 99s 322ms/step - loss: 0.0892 - accuracy: 0.9654 - val_loss: 17.8243 - val_accuracy: 0.7179\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 99s 322ms/step - loss: 0.0937 - accuracy: 0.9670 - val_loss: 0.7768 - val_accuracy: 0.7884\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 100s 323ms/step - loss: 0.0723 - accuracy: 0.9735 - val_loss: 1.4406 - val_accuracy: 0.7175\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 100s 323ms/step - loss: 0.0631 - accuracy: 0.9756 - val_loss: 1.4632 - val_accuracy: 0.8026\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 100s 325ms/step - loss: 0.0562 - accuracy: 0.9811 - val_loss: 20.5840 - val_accuracy: 0.7175\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0502 - accuracy: 0.9807 - val_loss: 12.2096 - val_accuracy: 0.7175\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 101s 326ms/step - loss: 0.0412 - accuracy: 0.9838 - val_loss: 45.6172 - val_accuracy: 0.7183\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0435 - accuracy: 0.9840 - val_loss: 8.8279 - val_accuracy: 0.7175\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 100s 322ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 80.8577 - val_accuracy: 0.7175\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 99s 319ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 10.4582 - val_accuracy: 0.7179\n",
      "Epoch 15/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 5.2403 - val_accuracy: 0.7377\n",
      "Epoch 16/50\n",
      "309/309 [==============================] - 99s 319ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 6.2460 - val_accuracy: 0.7207\n",
      "Epoch 17/50\n",
      "309/309 [==============================] - 100s 322ms/step - loss: 0.0301 - accuracy: 0.9891 - val_loss: 13.5416 - val_accuracy: 0.7519\n",
      "Epoch 18/50\n",
      "309/309 [==============================] - 99s 322ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 12.3901 - val_accuracy: 0.7300\n",
      "Epoch 19/50\n",
      "309/309 [==============================] - 99s 322ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 20.0686 - val_accuracy: 0.7179\n",
      "Epoch 20/50\n",
      "309/309 [==============================] - 98s 318ms/step - loss: 0.0162 - accuracy: 0.9936 - val_loss: 6.4961 - val_accuracy: 0.7418\n",
      "Epoch 21/50\n",
      "309/309 [==============================] - 100s 324ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 6.0162 - val_accuracy: 0.5403\n",
      "Epoch 22/50\n",
      "309/309 [==============================] - 102s 330ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 14.9212 - val_accuracy: 0.7207\n",
      "Epoch 23/50\n",
      "309/309 [==============================] - 98s 318ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 20.2706 - val_accuracy: 0.7183\n",
      "Epoch 24/50\n",
      "309/309 [==============================] - 100s 323ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 28.7647 - val_accuracy: 0.7179\n",
      "Epoch 25/50\n",
      "309/309 [==============================] - 101s 327ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 1184.2499 - val_accuracy: 0.7175\n",
      "Epoch 26/50\n",
      "309/309 [==============================] - 98s 318ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 12.4428 - val_accuracy: 0.8731\n",
      "Epoch 27/50\n",
      "309/309 [==============================] - 100s 325ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 9.2755 - val_accuracy: 0.5014\n",
      "Epoch 28/50\n",
      "309/309 [==============================] - 99s 319ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 70.8651 - val_accuracy: 0.7175\n",
      "Epoch 29/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 25.4260 - val_accuracy: 0.7179\n",
      "Epoch 30/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 1.9651 - val_accuracy: 0.8739\n",
      "Epoch 31/50\n",
      "309/309 [==============================] - 99s 321ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 10.5676 - val_accuracy: 0.5420\n",
      "Epoch 32/50\n",
      "309/309 [==============================] - 98s 316ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 2.6356 - val_accuracy: 0.7349\n",
      "Epoch 33/50\n",
      "309/309 [==============================] - 98s 317ms/step - loss: 0.0181 - accuracy: 0.9931 - val_loss: 24.2787 - val_accuracy: 0.6080\n",
      "Epoch 34/50\n",
      "309/309 [==============================] - 100s 323ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 5.8269 - val_accuracy: 0.8427\n",
      "Epoch 35/50\n",
      "309/309 [==============================] - 98s 317ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 3.6464 - val_accuracy: 0.8123\n",
      "Epoch 36/50\n",
      "309/309 [==============================] - 98s 317ms/step - loss: 0.0112 - accuracy: 0.9955 - val_loss: 131.5886 - val_accuracy: 0.3737\n",
      "Epoch 37/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 2.0638 - val_accuracy: 0.6729\n",
      "Epoch 38/50\n",
      "309/309 [==============================] - 98s 319ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 1.4510 - val_accuracy: 0.6854\n",
      "Epoch 39/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 1.9982 - val_accuracy: 0.7811\n",
      "Epoch 40/50\n",
      "309/309 [==============================] - 98s 318ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 1.3388 - val_accuracy: 0.8302\n",
      "Epoch 41/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 3.1057 - val_accuracy: 0.7645\n",
      "Epoch 42/50\n",
      "309/309 [==============================] - 97s 315ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 4.7737 - val_accuracy: 0.7483\n",
      "Epoch 43/50\n",
      "309/309 [==============================] - 98s 317ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 2.1193 - val_accuracy: 0.7612\n",
      "Epoch 44/50\n",
      "309/309 [==============================] - 98s 316ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 4.0111 - val_accuracy: 0.6996\n",
      "Epoch 45/50\n",
      "309/309 [==============================] - 97s 315ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.9516 - val_accuracy: 0.7848\n",
      "Epoch 46/50\n",
      "309/309 [==============================] - 99s 320ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.9898 - val_accuracy: 0.8541\n",
      "Epoch 47/50\n",
      "309/309 [==============================] - 97s 315ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 1.6982 - val_accuracy: 0.8221\n",
      "Epoch 48/50\n",
      "309/309 [==============================] - 98s 318ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 1.3414 - val_accuracy: 0.8273\n",
      "Epoch 49/50\n",
      "309/309 [==============================] - 98s 316ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 1.7369 - val_accuracy: 0.7953\n",
      "Epoch 50/50\n",
      "309/309 [==============================] - 99s 321ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 2.0529 - val_accuracy: 0.8703\n",
      "97/97 - 4s - loss: 1.9141 - accuracy: 0.8826 - 4s/epoch - 42ms/step\n",
      "\n",
      "Test accuracy: 0.8826199769973755\n",
      "97/97 [==============================] - 7s 39ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.87      0.98      0.92      2208\n",
      "    landslide       0.93      0.63      0.75       876\n",
      "\n",
      "     accuracy                           0.88      3084\n",
      "    macro avg       0.90      0.81      0.84      3084\n",
      " weighted avg       0.89      0.88      0.87      3084\n",
      "\n",
      "Accuracy: 0.6324849732774153\n",
      "Precision: 0.6335616438356164\n",
      "Recall: 0.6335616438356164\n",
      "F1 Score: 0.6335616438356164\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import NASNetMobile, Xception\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"TrainData_3/TrainData_3\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用NASNetMobile）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = NASNetMobile(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用Xception）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = Xception(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f49ad5-aee8-4f62-87b1-908e809eaeba",
   "metadata": {},
   "source": [
    "# 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d3577-03f4-43a6-8fc8-90e340706424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb604d0-fe5f-4962-ab0b-efc2c10827cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
