{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c9c094-5f16-4f18-97f1-38bad91cd6ac",
   "metadata": {},
   "source": [
    "# Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4461a9d-caf4-4e4d-845e-ca7323af541d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8093\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94234, saving model to best_model.h5\n",
      "278/278 [==============================] - 110s 314ms/step - loss: 0.3974 - accuracy: 0.8093 - val_loss: 0.1259 - val_accuracy: 0.9423\n",
      "Epoch 2/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9432\n",
      "Epoch 2: val_accuracy improved from 0.94234 to 0.97477, saving model to best_model.h5\n",
      "278/278 [==============================] - 84s 304ms/step - loss: 0.1503 - accuracy: 0.9432 - val_loss: 0.0757 - val_accuracy: 0.9748\n",
      "Epoch 3/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9739\n",
      "Epoch 3: val_accuracy did not improve from 0.97477\n",
      "278/278 [==============================] - 83s 297ms/step - loss: 0.0839 - accuracy: 0.9739 - val_loss: 0.0904 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9842\n",
      "Epoch 4: val_accuracy did not improve from 0.97477\n",
      "278/278 [==============================] - 82s 294ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 0.1266 - val_accuracy: 0.9586\n",
      "Epoch 5/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9856\n",
      "Epoch 5: val_accuracy improved from 0.97477 to 0.97838, saving model to best_model.h5\n",
      "278/278 [==============================] - 84s 302ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.0883 - val_accuracy: 0.9784\n",
      "Epoch 6/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9874\n",
      "Epoch 6: val_accuracy did not improve from 0.97838\n",
      "278/278 [==============================] - 82s 295ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0639 - val_accuracy: 0.9766\n",
      "Epoch 7/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9928\n",
      "Epoch 7: val_accuracy did not improve from 0.97838\n",
      "278/278 [==============================] - 82s 295ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0793 - val_accuracy: 0.9784\n",
      "Epoch 8/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 8: val_accuracy improved from 0.97838 to 0.98198, saving model to best_model.h5\n",
      "278/278 [==============================] - 85s 305ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.0767 - val_accuracy: 0.9820\n",
      "Epoch 9/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9905\n",
      "Epoch 9: val_accuracy did not improve from 0.98198\n",
      "278/278 [==============================] - 83s 297ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.0722 - val_accuracy: 0.9820\n",
      "Epoch 10/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 10: val_accuracy improved from 0.98198 to 0.98739, saving model to best_model.h5\n",
      "278/278 [==============================] - 83s 299ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0546 - val_accuracy: 0.9874\n",
      "Epoch 11/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9910\n",
      "Epoch 11: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 81s 292ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.1699 - val_accuracy: 0.9658\n",
      "Epoch 12/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9946\n",
      "Epoch 12: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 295ms/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.1123 - val_accuracy: 0.9784\n",
      "Epoch 13/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9950\n",
      "Epoch 13: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 295ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0981 - val_accuracy: 0.9712\n",
      "Epoch 14/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 9.1528e-04 - accuracy: 1.0000\n",
      "Epoch 14: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 295ms/step - loss: 9.1528e-04 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9802\n",
      "Epoch 15/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n",
      "Epoch 15: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 295ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0950 - val_accuracy: 0.9730\n",
      "Epoch 16/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 16: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 81s 290ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1131 - val_accuracy: 0.9730\n",
      "Epoch 17/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9905\n",
      "Epoch 17: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 294ms/step - loss: 0.0386 - accuracy: 0.9905 - val_loss: 0.0561 - val_accuracy: 0.9874\n",
      "Epoch 18/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9946\n",
      "Epoch 18: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 297ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.0853 - val_accuracy: 0.9784\n",
      "Epoch 19/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9838\n",
      "Epoch 19: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 81s 292ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.1031 - val_accuracy: 0.9802\n",
      "Epoch 20/20\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9964\n",
      "Epoch 20: val_accuracy did not improve from 0.98739\n",
      "278/278 [==============================] - 82s 294ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.1092 - val_accuracy: 0.9748\n",
      "18/18 [==============================] - 6s 135ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.99      0.99      0.99       399\n",
      "    landslide       0.98      0.98      0.98       156\n",
      "\n",
      "     accuracy                           0.99       555\n",
      "    macro avg       0.99      0.99      0.99       555\n",
      " weighted avg       0.99      0.99      0.99       555\n",
      "\n",
      "Accuracy: 0.9892\n",
      "Precision: 0.9892\n",
      "Recall: 0.9892\n",
      "F1 Score: 0.9892\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input, Dropout, Conv2D, SeparableConv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Conv2D, Multiply, LayerNormalization, MultiHeadAttention, Add, Flatten\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "data_path = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "img_size = (224, 224)\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "def spatial_attention_module(input_feature):\n",
    "    # 使用一个1x1的卷积层来生成注意力图\n",
    "    attention = Conv2D(1, (1, 1), activation='sigmoid')(input_feature)\n",
    "    # 将注意力图乘以原特征图来增强重要特征\n",
    "    enhanced_feature = Multiply()([input_feature, attention])\n",
    "    return enhanced_feature\n",
    "\n",
    "def build_image_model(input_shape):\n",
    "    img_input = Input(shape=input_shape, name='image_input')\n",
    "    img_base_model = EfficientNetB7(include_top=False, input_tensor=img_input, weights='imagenet')\n",
    "    img_features = img_base_model.output\n",
    "    img_features = spatial_attention_module(img_features)\n",
    "    img_features = GlobalAveragePooling2D()(img_features)\n",
    "    return Model(inputs=img_input, outputs=img_features, name='ImageModel')\n",
    "\n",
    "def load_images(folder, filenames, color_mode='rgb'):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        if filename.startswith('.'):  # 过滤掉隐藏文件\n",
    "            continue\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = load_img(img_path, target_size=img_size, color_mode=color_mode)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def transformer_block(x, num_heads=4):\n",
    "    # Layer Normalization\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    # Multi-head self-attention\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=64)(x_norm, x_norm)\n",
    "    # Skip connection\n",
    "    x = Add()([x, attn_output])\n",
    "    # Another layer normalization\n",
    "    x_norm = LayerNormalization()(x)\n",
    "    # Feed-forward network\n",
    "    ff_output = Dense(units=512, activation='relu')(x_norm)\n",
    "    # Final skip connection\n",
    "    output = Add()([x, ff_output])\n",
    "    return output\n",
    "\n",
    "def prepare_dataset(data_path):\n",
    "    landslide_path = os.path.join(data_path, \"landslide\")\n",
    "    non_landslide_path = os.path.join(data_path, \"non-landslide\")\n",
    "    \n",
    "    landslide_filenames = [filename for filename in os.listdir(os.path.join(landslide_path, \"image\")) if not filename.startswith('.')]\n",
    "    non_landslide_filenames = [filename for filename in os.listdir(os.path.join(non_landslide_path, \"image\")) if not filename.startswith('.')]\n",
    "\n",
    "    landslide_images = load_images(os.path.join(landslide_path, \"image\"), landslide_filenames)\n",
    "    landslide_dems = load_images(os.path.join(landslide_path, \"dem\"), landslide_filenames, color_mode='grayscale')\n",
    "    non_landslide_images = load_images(os.path.join(non_landslide_path, \"image\"), non_landslide_filenames)\n",
    "    non_landslide_dems = load_images(os.path.join(non_landslide_path, \"dem\"), non_landslide_filenames, color_mode='grayscale')\n",
    "\n",
    "    landslide_labels = np.ones(len(landslide_filenames), dtype=int)\n",
    "    non_landslide_labels = np.zeros(len(non_landslide_filenames), dtype=int)\n",
    "\n",
    "    images = np.concatenate([landslide_images, non_landslide_images], axis=0)\n",
    "    dems = np.concatenate([landslide_dems, non_landslide_dems], axis=0)\n",
    "    labels = np.concatenate([landslide_labels, non_landslide_labels], axis=0)\n",
    "\n",
    "    return images, dems, labels\n",
    "\n",
    "\n",
    "images, dems, labels = prepare_dataset(data_path)\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "x_img_train, x_img_val, x_dem_train, x_dem_val, y_train, y_val = train_test_split(images, dems, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_dem_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape, name='dem_input')\n",
    "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, -1))(x)\n",
    "    x = transformer_block(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=inputs, outputs=x, name='Advanced_DEM_CNN')\n",
    "\n",
    "\n",
    "def build_vae_feature_merger(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    z_mean = Dense(64)(x)\n",
    "    z_log_var = Dense(64)(x)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "    encoder = Model(input_layer, [z_mean, z_log_var, z], name='vae_merger')\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "# Build the dual input model\n",
    "def build_dual_input_model(input_shape):\n",
    "    img_model = build_image_model(input_shape)\n",
    "    img_features = img_model.output\n",
    "\n",
    "    dem_input_shape = (img_size[0], img_size[1], 1)  \n",
    "    dem_model = build_dem_cnn_model(dem_input_shape)\n",
    "    dem_features = dem_model.output\n",
    "\n",
    "    merged_features = Concatenate()([img_features, dem_features])\n",
    "    vae_encoder = build_vae_feature_merger(merged_features.shape[1])\n",
    "    z_mean, z_log_var, z = vae_encoder(merged_features)\n",
    "\n",
    "    x = Dense(256, activation='relu')(z)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[img_model.input, dem_model.input], outputs=output, name='DualInputModel')\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = build_dual_input_model(input_shape=(224, 224, 3))\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the checkpoint filepath\n",
    "checkpoint_filepath = 'best_model.h5'\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the ModelCheckpoint callback\n",
    "history = model.fit(\n",
    "    [x_img_train, x_dem_train],\n",
    "    y_train,\n",
    "    validation_data=([x_img_val, x_dem_val], y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint_callback]  # Pass the ModelCheckpoint callback here\n",
    ")\n",
    "\n",
    "# Load the best weights\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "# Predict using the best weights\n",
    "y_pred_probs = model.predict([x_img_val, x_dem_val])\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['non-landslide', 'landslide']))\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20306aa7-789d-4964-8d59-d0d9cf1ec269",
   "metadata": {},
   "source": [
    "## Other Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fcd73c-fad1-4fef-8193-179494b9e156",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 12s 107ms/step - loss: 37.7402 - accuracy: 0.7813 - val_loss: 248.1522 - val_accuracy: 0.7523\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.2899 - accuracy: 0.8912 - val_loss: 1.1469 - val_accuracy: 0.8378\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 5s 95ms/step - loss: 0.2820 - accuracy: 0.9250 - val_loss: 0.8555 - val_accuracy: 0.8221\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 5s 87ms/step - loss: 0.2733 - accuracy: 0.9205 - val_loss: 0.2301 - val_accuracy: 0.9099\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 4s 80ms/step - loss: 0.1595 - accuracy: 0.9340 - val_loss: 1.2882 - val_accuracy: 0.8649\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.1184 - accuracy: 0.9583 - val_loss: 0.1512 - val_accuracy: 0.9437\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.1045 - accuracy: 0.9611 - val_loss: 0.1279 - val_accuracy: 0.9414\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.5160 - accuracy: 0.9667 - val_loss: 7.9386 - val_accuracy: 0.7838\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.2256 - accuracy: 0.9211 - val_loss: 0.8910 - val_accuracy: 0.8378\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.1247 - accuracy: 0.9526 - val_loss: 0.2340 - val_accuracy: 0.9302\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0828 - accuracy: 0.9696 - val_loss: 0.1598 - val_accuracy: 0.9595\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.2285 - accuracy: 0.9724 - val_loss: 1.4786 - val_accuracy: 0.8288\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.1185 - accuracy: 0.9589 - val_loss: 0.2798 - val_accuracy: 0.9302\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.2427 - val_accuracy: 0.9414\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 5s 84ms/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 0.5727 - val_accuracy: 0.8536\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 6s 100ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 0.2785 - val_accuracy: 0.9144\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 5s 85ms/step - loss: 0.0251 - accuracy: 0.9904 - val_loss: 0.1720 - val_accuracy: 0.9482\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.1160 - val_accuracy: 0.9685\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 5s 86ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0836 - val_accuracy: 0.9730\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 5s 89ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.5167 - val_accuracy: 0.8986\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.1929 - val_accuracy: 0.9347\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 5s 83ms/step - loss: 0.0937 - accuracy: 0.9713 - val_loss: 0.1516 - val_accuracy: 0.9595\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.2442 - val_accuracy: 0.9257\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.2173 - val_accuracy: 0.9279\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0372 - accuracy: 0.9927 - val_loss: 0.4684 - val_accuracy: 0.8941\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.2701 - val_accuracy: 0.9482\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 5s 91ms/step - loss: 0.0464 - accuracy: 0.9893 - val_loss: 0.3090 - val_accuracy: 0.9189\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 5s 90ms/step - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.3653 - val_accuracy: 0.9144\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.1665 - val_accuracy: 0.9617\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 5s 88ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.1452 - val_accuracy: 0.9505\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 5s 96ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.1660 - val_accuracy: 0.9505\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 5s 83ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1450 - val_accuracy: 0.9595\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.2153 - val_accuracy: 0.9437\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 5s 84ms/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.1489 - val_accuracy: 0.9662\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.2048 - val_accuracy: 0.9414\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.3509 - val_accuracy: 0.9212\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1800 - val_accuracy: 0.9595\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 4s 80ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 0.3474 - val_accuracy: 0.9257\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0431 - accuracy: 0.9882 - val_loss: 0.1983 - val_accuracy: 0.9324\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.2337 - val_accuracy: 0.9369\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 5s 94ms/step - loss: 0.0238 - accuracy: 0.9904 - val_loss: 0.2896 - val_accuracy: 0.9257\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 5s 92ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.8472 - val_accuracy: 0.8806\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 5s 82ms/step - loss: 0.0099 - accuracy: 0.9955 - val_loss: 0.3978 - val_accuracy: 0.9144\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 5s 85ms/step - loss: 0.0112 - accuracy: 0.9955 - val_loss: 0.1728 - val_accuracy: 0.9414\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 5s 95ms/step - loss: 0.0582 - accuracy: 0.9758 - val_loss: 0.2817 - val_accuracy: 0.9212\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 5s 83ms/step - loss: 0.0550 - accuracy: 0.9859 - val_loss: 0.7499 - val_accuracy: 0.8694\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0369 - accuracy: 0.9910 - val_loss: 0.3681 - val_accuracy: 0.9347\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 4s 80ms/step - loss: 0.0442 - accuracy: 0.9870 - val_loss: 1.1010 - val_accuracy: 0.8086\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0750 - accuracy: 0.9763 - val_loss: 0.2479 - val_accuracy: 0.9212\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 5s 81ms/step - loss: 0.0624 - accuracy: 0.9763 - val_loss: 0.3629 - val_accuracy: 0.8851\n",
      "18/18 - 1s - loss: 0.3931 - accuracy: 0.8685 - 629ms/epoch - 35ms/step\n",
      "\n",
      "Test accuracy: 0.8684684634208679\n",
      "18/18 [==============================] - 1s 26ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.85      1.00      0.92       399\n",
      "    landslide       0.99      0.54      0.70       156\n",
      "\n",
      "     accuracy                           0.87       555\n",
      "    macro avg       0.92      0.77      0.81       555\n",
      " weighted avg       0.89      0.87      0.85       555\n",
      "\n",
      "Accuracy: 0.651862673484295\n",
      "Precision: 0.5384615384615384\n",
      "Recall: 0.5384615384615384\n",
      "F1 Score: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用ResNet50）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = ResNet50(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用简单的CNN模型）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(input_dem)\n",
    "dem_pool1 = MaxPooling2D(pool_size=(2, 2))(dem_conv1)\n",
    "dem_conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(dem_pool1)\n",
    "dem_pool2 = MaxPooling2D(pool_size=(2, 2))(dem_conv2)\n",
    "dem_flat = Flatten()(dem_pool2)\n",
    "dem_output = Dense(256, activation='relu')(dem_flat)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfa415e-fbff-47e9-adbb-3a4ac036bef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 18s 181ms/step - loss: 1.4719 - accuracy: 0.6815 - val_loss: 293.0383 - val_accuracy: 0.7523\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 7s 130ms/step - loss: 0.5777 - accuracy: 0.7142 - val_loss: 0.6067 - val_accuracy: 0.7523\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 7s 133ms/step - loss: 0.5755 - accuracy: 0.7159 - val_loss: 0.5171 - val_accuracy: 0.7523\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.5470 - accuracy: 0.7193 - val_loss: 0.5026 - val_accuracy: 0.7590\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.5639 - accuracy: 0.7153 - val_loss: 0.5108 - val_accuracy: 0.7523\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 8s 139ms/step - loss: 0.5569 - accuracy: 0.7142 - val_loss: 0.4869 - val_accuracy: 0.7635\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 7s 125ms/step - loss: 0.5540 - accuracy: 0.7114 - val_loss: 0.4419 - val_accuracy: 0.7725\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.4657 - accuracy: 0.7554 - val_loss: 0.4241 - val_accuracy: 0.8131\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.4881 - accuracy: 0.7773 - val_loss: 0.4476 - val_accuracy: 0.7725\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.4613 - accuracy: 0.7813 - val_loss: 0.3706 - val_accuracy: 0.8288\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.4273 - accuracy: 0.8067 - val_loss: 0.4066 - val_accuracy: 0.8131\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.4816 - accuracy: 0.7773 - val_loss: 0.5672 - val_accuracy: 0.7545\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.4800 - accuracy: 0.7649 - val_loss: 0.3601 - val_accuracy: 0.8671\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 8s 136ms/step - loss: 0.3677 - accuracy: 0.8568 - val_loss: 0.3520 - val_accuracy: 0.8514\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.4690 - accuracy: 0.7841 - val_loss: 0.3873 - val_accuracy: 0.8221\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 7s 125ms/step - loss: 0.3965 - accuracy: 0.8185 - val_loss: 0.3311 - val_accuracy: 0.8514\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.3763 - accuracy: 0.8275 - val_loss: 0.4537 - val_accuracy: 0.7613\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 8s 139ms/step - loss: 0.3546 - accuracy: 0.8551 - val_loss: 0.3225 - val_accuracy: 0.8491\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.3215 - accuracy: 0.8703 - val_loss: 0.3492 - val_accuracy: 0.8761\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.3925 - accuracy: 0.8309 - val_loss: 1.2609 - val_accuracy: 0.7523\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 8s 140ms/step - loss: 0.3651 - accuracy: 0.8687 - val_loss: 0.2945 - val_accuracy: 0.8716\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.3135 - accuracy: 0.8844 - val_loss: 0.2407 - val_accuracy: 0.9077\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 7s 128ms/step - loss: 0.2438 - accuracy: 0.9014 - val_loss: 0.2115 - val_accuracy: 0.9077\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 7s 125ms/step - loss: 0.2243 - accuracy: 0.9183 - val_loss: 0.4203 - val_accuracy: 0.8018\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.2192 - accuracy: 0.9160 - val_loss: 0.1698 - val_accuracy: 0.9234\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.2033 - accuracy: 0.9205 - val_loss: 0.2400 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 7s 128ms/step - loss: 0.1840 - accuracy: 0.9380 - val_loss: 0.2570 - val_accuracy: 0.9122\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.1716 - accuracy: 0.9386 - val_loss: 0.6271 - val_accuracy: 0.6374\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.2105 - accuracy: 0.9166 - val_loss: 0.1990 - val_accuracy: 0.9324\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 7s 126ms/step - loss: 0.1764 - accuracy: 0.9307 - val_loss: 0.1944 - val_accuracy: 0.9257\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.1480 - accuracy: 0.9498 - val_loss: 0.3228 - val_accuracy: 0.8851\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.1620 - accuracy: 0.9380 - val_loss: 0.2471 - val_accuracy: 0.8964\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 7s 126ms/step - loss: 0.1369 - accuracy: 0.9476 - val_loss: 0.1419 - val_accuracy: 0.9527\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 7s 128ms/step - loss: 0.1404 - accuracy: 0.9498 - val_loss: 0.2558 - val_accuracy: 0.8694\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.1115 - accuracy: 0.9600 - val_loss: 0.2476 - val_accuracy: 0.9279\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 7s 133ms/step - loss: 0.1536 - accuracy: 0.9414 - val_loss: 0.1277 - val_accuracy: 0.9527\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.1474 - accuracy: 0.9510 - val_loss: 0.1630 - val_accuracy: 0.9302\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 7s 127ms/step - loss: 0.1127 - accuracy: 0.9566 - val_loss: 0.1472 - val_accuracy: 0.9369\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 7s 131ms/step - loss: 0.0982 - accuracy: 0.9628 - val_loss: 0.1591 - val_accuracy: 0.9459\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.1204 - accuracy: 0.9549 - val_loss: 0.1897 - val_accuracy: 0.9392\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.0924 - accuracy: 0.9679 - val_loss: 0.2078 - val_accuracy: 0.9234\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.1283 - accuracy: 0.9583 - val_loss: 0.2050 - val_accuracy: 0.9212\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.1534 - accuracy: 0.9543 - val_loss: 0.1689 - val_accuracy: 0.9392\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.0972 - accuracy: 0.9622 - val_loss: 0.1654 - val_accuracy: 0.9324\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 7s 122ms/step - loss: 0.1109 - accuracy: 0.9605 - val_loss: 0.2843 - val_accuracy: 0.8964\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 7s 132ms/step - loss: 0.0795 - accuracy: 0.9707 - val_loss: 0.3405 - val_accuracy: 0.9234\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 7s 127ms/step - loss: 0.0799 - accuracy: 0.9701 - val_loss: 0.1530 - val_accuracy: 0.9369\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 7s 123ms/step - loss: 0.0813 - accuracy: 0.9713 - val_loss: 0.1529 - val_accuracy: 0.9550\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 7s 128ms/step - loss: 0.0969 - accuracy: 0.9651 - val_loss: 0.1646 - val_accuracy: 0.9369\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 7s 124ms/step - loss: 0.0516 - accuracy: 0.9814 - val_loss: 0.2652 - val_accuracy: 0.9414\n",
      "18/18 - 1s - loss: 0.2778 - accuracy: 0.9297 - 1s/epoch - 67ms/step\n",
      "\n",
      "Test accuracy: 0.929729700088501\n",
      "18/18 [==============================] - 2s 39ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.94      0.96      0.95       399\n",
      "    landslide       0.90      0.84      0.87       156\n",
      "\n",
      "     accuracy                           0.93       555\n",
      "    macro avg       0.92      0.90      0.91       555\n",
      " weighted avg       0.93      0.93      0.93       555\n",
      "\n",
      "Accuracy: 0.6045288531775018\n",
      "Precision: 0.8397435897435898\n",
      "Recall: 0.8397435897435898\n",
      "F1 Score: 0.8397435897435898\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用VGG16）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = VGG16(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用InceptionV3）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973ef10a-e7bb-4ccb-b567-4d6f56454e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 11:35:22.958020: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 11:35:36.746160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 11:35:37.181305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22134 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1b:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 11:35:51.244375: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-13 11:35:51.934578: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-13 11:35:51.934595: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-13 11:35:51.934666: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-13 11:35:52.720975: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 23s 195ms/step - loss: 0.4982 - accuracy: 0.8106 - val_loss: 134.5846 - val_accuracy: 0.7365\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 10s 183ms/step - loss: 0.2596 - accuracy: 0.9115 - val_loss: 47.5036 - val_accuracy: 0.7230\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 10s 180ms/step - loss: 0.1773 - accuracy: 0.9436 - val_loss: 2.3851 - val_accuracy: 0.7545\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.1328 - accuracy: 0.9583 - val_loss: 0.6486 - val_accuracy: 0.8806\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 0.1449 - accuracy: 0.9538 - val_loss: 8.0047 - val_accuracy: 0.7635\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.1155 - accuracy: 0.9583 - val_loss: 0.8783 - val_accuracy: 0.8919\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.0689 - accuracy: 0.9752 - val_loss: 0.6176 - val_accuracy: 0.8514\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 10s 170ms/step - loss: 0.0769 - accuracy: 0.9746 - val_loss: 0.2014 - val_accuracy: 0.9482\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 10s 173ms/step - loss: 0.0848 - accuracy: 0.9701 - val_loss: 0.3716 - val_accuracy: 0.8941\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 10s 170ms/step - loss: 0.0377 - accuracy: 0.9848 - val_loss: 1.4013 - val_accuracy: 0.7860\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 10s 172ms/step - loss: 0.0744 - accuracy: 0.9797 - val_loss: 1.1057 - val_accuracy: 0.8829\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 10s 171ms/step - loss: 0.0792 - accuracy: 0.9791 - val_loss: 0.5756 - val_accuracy: 0.8919\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 10s 170ms/step - loss: 0.0538 - accuracy: 0.9791 - val_loss: 0.2142 - val_accuracy: 0.9212\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.8284 - val_accuracy: 0.8716\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.7460 - val_accuracy: 0.8941\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.0679 - accuracy: 0.9797 - val_loss: 1.8265 - val_accuracy: 0.7815\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0692 - accuracy: 0.9735 - val_loss: 1.7851 - val_accuracy: 0.7838\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0253 - accuracy: 0.9899 - val_loss: 0.1820 - val_accuracy: 0.9707\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 9s 166ms/step - loss: 0.0097 - accuracy: 0.9961 - val_loss: 0.3541 - val_accuracy: 0.9527\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.5252 - val_accuracy: 0.9122\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.3044 - val_accuracy: 0.9347\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 10s 171ms/step - loss: 0.0413 - accuracy: 0.9853 - val_loss: 0.9598 - val_accuracy: 0.8941\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 10s 182ms/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 1.1388 - val_accuracy: 0.8108\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0322 - accuracy: 0.9876 - val_loss: 0.6267 - val_accuracy: 0.8356\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.5292 - val_accuracy: 0.9257\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.1389 - val_accuracy: 0.9595\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.3795 - val_accuracy: 0.8874\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 1.4599 - val_accuracy: 0.7613\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.4700 - val_accuracy: 0.9257\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0621 - accuracy: 0.9791 - val_loss: 0.4384 - val_accuracy: 0.8221\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0521 - accuracy: 0.9775 - val_loss: 0.3039 - val_accuracy: 0.9392\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.4482 - val_accuracy: 0.9189\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.5995 - val_accuracy: 0.9122\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.1025 - accuracy: 0.9690 - val_loss: 2.7363 - val_accuracy: 0.7748\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.3555 - val_accuracy: 0.9527\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.8644 - val_accuracy: 0.8581\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0592 - accuracy: 0.9831 - val_loss: 0.3199 - val_accuracy: 0.9324\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.2984 - val_accuracy: 0.9459\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.3886 - val_accuracy: 0.9369\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.4996 - val_accuracy: 0.9279\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.2832 - val_accuracy: 0.9459\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0269 - accuracy: 0.9904 - val_loss: 1.2174 - val_accuracy: 0.8266\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0280 - accuracy: 0.9949 - val_loss: 1.6306 - val_accuracy: 0.8131\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 2.2267 - val_accuracy: 0.8018\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 1.0744 - val_accuracy: 0.8626\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 1.8006 - val_accuracy: 0.8333\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0406 - accuracy: 0.9825 - val_loss: 0.4707 - val_accuracy: 0.8739\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.2003 - val_accuracy: 0.9527\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.1743 - val_accuracy: 0.9572\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 9s 158ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.2531 - val_accuracy: 0.9369\n",
      "18/18 - 1s - loss: 0.3996 - accuracy: 0.9297 - 830ms/epoch - 46ms/step\n",
      "\n",
      "Test accuracy: 0.929729700088501\n",
      "18/18 [==============================] - 2s 34ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.93      0.97      0.95       399\n",
      "    landslide       0.93      0.81      0.87       156\n",
      "\n",
      "     accuracy                           0.93       555\n",
      "    macro avg       0.93      0.89      0.91       555\n",
      " weighted avg       0.93      0.93      0.93       555\n",
      "\n",
      "Accuracy: 0.6108400292184076\n",
      "Precision: 0.8141025641025641\n",
      "Recall: 0.8141025641025641\n",
      "F1 Score: 0.8141025641025641\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用ResNet50）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = ResNet50(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用MobileNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46e7bea-2180-455d-952c-4d3e55ca7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 11:59:58.884454: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 12:00:12.912068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 12:00:13.332656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22134 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:39:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 12:00:25.916309: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-13 12:00:26.561397: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-13 12:00:26.561414: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-13 12:00:26.561497: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-13 12:00:27.376543: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 27s 287ms/step - loss: 0.2652 - accuracy: 0.8963 - val_loss: 6.2467 - val_accuracy: 0.7725\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 15s 260ms/step - loss: 0.1569 - accuracy: 0.9560 - val_loss: 10.0856 - val_accuracy: 0.2477\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 14s 258ms/step - loss: 0.0890 - accuracy: 0.9701 - val_loss: 8.4199 - val_accuracy: 0.2477\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 0.0904 - accuracy: 0.9690 - val_loss: 9.6985 - val_accuracy: 0.3131\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 6.4101 - val_accuracy: 0.4482\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 7.8207 - val_accuracy: 0.3311\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 0.0640 - accuracy: 0.9769 - val_loss: 15.1759 - val_accuracy: 0.2477\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 11.0322 - val_accuracy: 0.2477\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0428 - accuracy: 0.9876 - val_loss: 12.3156 - val_accuracy: 0.2568\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0543 - accuracy: 0.9814 - val_loss: 9.2166 - val_accuracy: 0.2477\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 6.4965 - val_accuracy: 0.5090\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 10.1779 - val_accuracy: 0.2635\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 0.0430 - accuracy: 0.9876 - val_loss: 17.8780 - val_accuracy: 0.2477\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 13.3746 - val_accuracy: 0.2477\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 15.9680 - val_accuracy: 0.2500\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 17.2592 - val_accuracy: 0.2477\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 0.0524 - accuracy: 0.9865 - val_loss: 2.5274 - val_accuracy: 0.6374\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 3.5833 - val_accuracy: 0.6914\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.5689 - val_accuracy: 0.7095\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0270 - accuracy: 0.9932 - val_loss: 5.3692 - val_accuracy: 0.6351\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0344 - accuracy: 0.9904 - val_loss: 7.2629 - val_accuracy: 0.4685\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 10.5473 - val_accuracy: 0.3694\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 12.5734 - val_accuracy: 0.3626\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 2.7794 - val_accuracy: 0.7207\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 5.7772 - val_accuracy: 0.5811\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 13s 224ms/step - loss: 0.0291 - accuracy: 0.9899 - val_loss: 6.9777 - val_accuracy: 0.5158\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 3.2953 - val_accuracy: 0.7545\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 3.2365 - val_accuracy: 0.7523\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 0.0381 - accuracy: 0.9904 - val_loss: 1.6747 - val_accuracy: 0.7387\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 10.3582 - val_accuracy: 0.2973\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 14.3231 - val_accuracy: 0.2928\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 9.6778 - val_accuracy: 0.3446\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 14.4182 - val_accuracy: 0.2477\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0179 - accuracy: 0.9927 - val_loss: 16.3570 - val_accuracy: 0.2590\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 0.0155 - accuracy: 0.9927 - val_loss: 25.3268 - val_accuracy: 0.2635\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0163 - accuracy: 0.9938 - val_loss: 12.1000 - val_accuracy: 0.3468\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 14.4278 - val_accuracy: 0.2793\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 6.1310 - val_accuracy: 0.4099\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 1.7743 - val_accuracy: 0.7162\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.5392 - val_accuracy: 0.8221\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.8499 - val_accuracy: 0.8536\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 1.8773 - val_accuracy: 0.7725\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 7.7576e-04 - accuracy: 1.0000 - val_loss: 1.2696 - val_accuracy: 0.8266\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.3535 - val_accuracy: 0.9324\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.5565 - val_accuracy: 0.9189\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.9833 - val_accuracy: 0.8649\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 1.0498 - val_accuracy: 0.8806\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 13s 229ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4417 - val_accuracy: 0.9459\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 13s 224ms/step - loss: 5.4520e-04 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9527\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 13s 234ms/step - loss: 1.4527e-04 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9527\n",
      "18/18 - 1s - loss: 0.5129 - accuracy: 0.9459 - 864ms/epoch - 48ms/step\n",
      "\n",
      "Test accuracy: 0.9459459185600281\n",
      "18/18 [==============================] - 2s 34ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.98      0.95      0.96       399\n",
      "    landslide       0.88      0.94      0.91       156\n",
      "\n",
      "     accuracy                           0.95       555\n",
      "    macro avg       0.93      0.94      0.93       555\n",
      " weighted avg       0.95      0.95      0.95       555\n",
      "\n",
      "Accuracy: 0.5863842220598977\n",
      "Precision: 0.9423076923076923\n",
      "Recall: 0.9423076923076923\n",
      "F1 Score: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNetV2）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用Xception）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = Xception(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68baa887-63ea-4399-b8dd-dfdfd4d769e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 22s 199ms/step - loss: 0.2480 - accuracy: 0.9092 - val_loss: 0.5549 - val_accuracy: 0.9099\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0831 - accuracy: 0.9729 - val_loss: 0.2890 - val_accuracy: 0.9324\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 10s 184ms/step - loss: 0.0836 - accuracy: 0.9735 - val_loss: 0.1958 - val_accuracy: 0.9324\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 10s 172ms/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 0.0429 - val_accuracy: 0.9865\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.0486 - accuracy: 0.9814 - val_loss: 0.1374 - val_accuracy: 0.9640\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 0.0750 - val_accuracy: 0.9752\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.0301 - accuracy: 0.9870 - val_loss: 0.1061 - val_accuracy: 0.9730\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1191 - val_accuracy: 0.9730\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.0513 - accuracy: 0.9803 - val_loss: 0.1261 - val_accuracy: 0.9595\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.0355 - accuracy: 0.9876 - val_loss: 0.1676 - val_accuracy: 0.9640\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 0.1121 - val_accuracy: 0.9707\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0377 - accuracy: 0.9882 - val_loss: 0.2398 - val_accuracy: 0.9369\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0262 - accuracy: 0.9893 - val_loss: 0.1357 - val_accuracy: 0.9527\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.0784 - val_accuracy: 0.9752\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1018 - val_accuracy: 0.9752\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.2374 - val_accuracy: 0.9550\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 0.1397 - val_accuracy: 0.9730\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.3936 - val_accuracy: 0.8964\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.4847 - val_accuracy: 0.8243\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 10s 170ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.1213 - val_accuracy: 0.9617\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 0.1858 - val_accuracy: 0.9527\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1221 - val_accuracy: 0.9797\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.1010 - val_accuracy: 0.9707\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.0735 - val_accuracy: 0.9775\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0742 - val_accuracy: 0.9842\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 10s 171ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.1226 - val_accuracy: 0.9662\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.0204 - accuracy: 0.9955 - val_loss: 0.1477 - val_accuracy: 0.9640\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 10s 170ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.1079 - val_accuracy: 0.9775\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1226 - val_accuracy: 0.9730\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1499 - val_accuracy: 0.9685\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.2624 - val_accuracy: 0.9437\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 62.9128 - val_accuracy: 0.2477\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0474 - accuracy: 0.9870 - val_loss: 0.5270 - val_accuracy: 0.9347\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 10s 170ms/step - loss: 0.0372 - accuracy: 0.9859 - val_loss: 0.3112 - val_accuracy: 0.9414\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.2998 - val_accuracy: 0.9550\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.2521 - val_accuracy: 0.9662\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0833 - val_accuracy: 0.9842\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0849 - val_accuracy: 0.9775\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.1575 - val_accuracy: 0.9797\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.1265 - val_accuracy: 0.9685\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0990 - val_accuracy: 0.9707\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1619 - val_accuracy: 0.9662\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 0.1271 - val_accuracy: 0.9707\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1055 - val_accuracy: 0.9775\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 6.7466e-04 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9797\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 4.7842e-04 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9797\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 3.6117e-04 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9775\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 1.5960e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9820\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 1.3183e-04 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9775\n",
      "18/18 - 1s - loss: 0.1397 - accuracy: 0.9730 - 741ms/epoch - 41ms/step\n",
      "\n",
      "Test accuracy: 0.9729729890823364\n",
      "18/18 [==============================] - 2s 39ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.98      0.98      0.98       399\n",
      "    landslide       0.96      0.94      0.95       156\n",
      "\n",
      "     accuracy                           0.97       555\n",
      "    macro avg       0.97      0.96      0.97       555\n",
      " weighted avg       0.97      0.97      0.97       555\n",
      "\n",
      "Accuracy: 0.598217677136596\n",
      "Precision: 0.9423076923076923\n",
      "Recall: 0.9423076923076923\n",
      "F1 Score: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, DenseNet121\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNet）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNet(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用DenseNet121）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0543c36-268c-4c87-b762-bc08f797268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219055592/219055592 [==============================] - 8s 0us/step\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 35s 283ms/step - loss: 0.2934 - accuracy: 0.9014 - val_loss: 7.8982 - val_accuracy: 0.2477\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 12s 222ms/step - loss: 0.1427 - accuracy: 0.9436 - val_loss: 8.9434 - val_accuracy: 0.2477\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 12s 216ms/step - loss: 0.1165 - accuracy: 0.9628 - val_loss: 10.6325 - val_accuracy: 0.2477\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.1006 - accuracy: 0.9656 - val_loss: 7.6408 - val_accuracy: 0.2477\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0963 - accuracy: 0.9713 - val_loss: 8.0092 - val_accuracy: 0.3896\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 12s 213ms/step - loss: 0.0796 - accuracy: 0.9791 - val_loss: 7.0513 - val_accuracy: 0.4324\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 12s 214ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 9.9941 - val_accuracy: 0.4257\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 12s 220ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 9.9140 - val_accuracy: 0.5068\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 12s 210ms/step - loss: 0.0542 - accuracy: 0.9808 - val_loss: 6.7305 - val_accuracy: 0.3671\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 12s 209ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 3.0885 - val_accuracy: 0.7005\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 12s 216ms/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 5.0851 - val_accuracy: 0.6824\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 12s 219ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 4.6151 - val_accuracy: 0.7207\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 12s 211ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 5.6747 - val_accuracy: 0.6734\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 12s 208ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.5986 - val_accuracy: 0.7613\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 12s 208ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 3.8971 - val_accuracy: 0.7635\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 12s 218ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 6.9620 - val_accuracy: 0.5270\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 12s 218ms/step - loss: 0.0396 - accuracy: 0.9893 - val_loss: 2.7812 - val_accuracy: 0.7568\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 12s 210ms/step - loss: 0.0339 - accuracy: 0.9921 - val_loss: 1.5111 - val_accuracy: 0.7838\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.7393 - val_accuracy: 0.8604\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 12s 216ms/step - loss: 0.0603 - accuracy: 0.9825 - val_loss: 3.1201 - val_accuracy: 0.7432\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 12s 211ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 8.1931 - val_accuracy: 0.5811\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 12s 211ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 11.0241 - val_accuracy: 0.5405\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 2.3652 - val_accuracy: 0.7905\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 12s 219ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 1.0883 - val_accuracy: 0.8784\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 12s 212ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 1.0041 - val_accuracy: 0.8986\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 12s 207ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.8708 - val_accuracy: 0.9234\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 12s 215ms/step - loss: 1.5023e-04 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.9324\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 12s 220ms/step - loss: 8.0079e-05 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.9414\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 12s 220ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.5915 - val_accuracy: 0.9369\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 12s 210ms/step - loss: 0.0376 - accuracy: 0.9910 - val_loss: 1.4722 - val_accuracy: 0.8874\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 12s 214ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 5.7911 - val_accuracy: 0.8041\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 2.5508 - val_accuracy: 0.8491\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0330 - accuracy: 0.9904 - val_loss: 0.6192 - val_accuracy: 0.8919\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 12s 210ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.7243 - val_accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 12s 218ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.0280 - val_accuracy: 0.9302\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 12s 212ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 1.0877 - val_accuracy: 0.9032\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 12s 212ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.6069 - val_accuracy: 0.8581\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 12s 208ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.8110 - val_accuracy: 0.8986\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0187 - accuracy: 0.9915 - val_loss: 0.9761 - val_accuracy: 0.9054\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 12s 215ms/step - loss: 0.0088 - accuracy: 0.9961 - val_loss: 1.7282 - val_accuracy: 0.8739\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 12s 217ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 1.3125 - val_accuracy: 0.8581\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 12s 216ms/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 3.5420 - val_accuracy: 0.7905\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 12s 213ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 3.5523 - val_accuracy: 0.8176\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 12s 209ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 1.7589 - val_accuracy: 0.6824\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 12s 216ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.9588 - val_accuracy: 0.8829\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 12s 215ms/step - loss: 0.0236 - accuracy: 0.9910 - val_loss: 0.3588 - val_accuracy: 0.9099\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 12s 211ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.5247 - val_accuracy: 0.7950\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 12s 213ms/step - loss: 0.0056 - accuracy: 0.9966 - val_loss: 5.9107 - val_accuracy: 0.3356\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 12s 218ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.3976 - val_accuracy: 0.8604\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 12s 211ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.3256 - val_accuracy: 0.8761\n",
      "18/18 - 1s - loss: 1.7403 - accuracy: 0.8468 - 1s/epoch - 64ms/step\n",
      "\n",
      "Test accuracy: 0.8468468189239502\n",
      "18/18 [==============================] - 4s 56ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.96      0.82      0.88       399\n",
      "    landslide       0.67      0.92      0.77       156\n",
      "\n",
      "     accuracy                           0.85       555\n",
      "    macro avg       0.81      0.87      0.83       555\n",
      " weighted avg       0.88      0.85      0.85       555\n",
      "\n",
      "Accuracy: 0.5493060628195763\n",
      "Precision: 0.9166666666666666\n",
      "Recall: 0.9166666666666666\n",
      "F1 Score: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, InceptionResNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNetV2）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用InceptionResNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "dem_features = InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)(input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(dem_features)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d5692d-81d5-4ae2-9858-741b7288e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 19s 174ms/step - loss: 0.6861 - accuracy: 0.8608 - val_loss: 19.5984 - val_accuracy: 0.2477\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1674 - accuracy: 0.9363 - val_loss: 0.3421 - val_accuracy: 0.9099\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.1084 - accuracy: 0.9566 - val_loss: 0.5393 - val_accuracy: 0.8694\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1126 - accuracy: 0.9526 - val_loss: 0.1573 - val_accuracy: 0.9414\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1094 - accuracy: 0.9594 - val_loss: 0.2033 - val_accuracy: 0.9167\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1032 - accuracy: 0.9617 - val_loss: 0.9023 - val_accuracy: 0.9189\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0926 - accuracy: 0.9684 - val_loss: 8.7821 - val_accuracy: 0.8086\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0984 - accuracy: 0.9651 - val_loss: 0.2239 - val_accuracy: 0.9482\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 10s 177ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 1.1647 - val_accuracy: 0.7613\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0658 - accuracy: 0.9752 - val_loss: 0.2731 - val_accuracy: 0.9077\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0642 - accuracy: 0.9758 - val_loss: 0.5114 - val_accuracy: 0.9032\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0798 - accuracy: 0.9718 - val_loss: 0.1837 - val_accuracy: 0.9347\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.0550 - accuracy: 0.9797 - val_loss: 0.1758 - val_accuracy: 0.9505\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 0.3167 - val_accuracy: 0.9077\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.6319 - val_accuracy: 0.8941\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.3112 - val_accuracy: 0.9302\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0553 - accuracy: 0.9786 - val_loss: 0.2371 - val_accuracy: 0.9324\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0602 - accuracy: 0.9814 - val_loss: 0.1691 - val_accuracy: 0.9437\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0322 - accuracy: 0.9904 - val_loss: 0.1076 - val_accuracy: 0.9617\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.9837 - val_accuracy: 0.7365\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0372 - accuracy: 0.9853 - val_loss: 0.1010 - val_accuracy: 0.9572\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.2341 - val_accuracy: 0.9369\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.2238 - val_accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0688 - accuracy: 0.9741 - val_loss: 0.1596 - val_accuracy: 0.9527\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0254 - accuracy: 0.9904 - val_loss: 0.1542 - val_accuracy: 0.9572\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.4134 - val_accuracy: 0.9257\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0446 - accuracy: 0.9842 - val_loss: 0.1723 - val_accuracy: 0.9279\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.1031 - val_accuracy: 0.9707\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9640\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.0848 - val_accuracy: 0.9820\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0098 - accuracy: 0.9955 - val_loss: 0.1361 - val_accuracy: 0.9595\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 1.5840 - val_accuracy: 0.7838\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.1740 - val_accuracy: 0.9482\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.4768 - val_accuracy: 0.9122\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0151 - accuracy: 0.9932 - val_loss: 0.1502 - val_accuracy: 0.9347\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0541 - accuracy: 0.9842 - val_loss: 0.2941 - val_accuracy: 0.8941\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.1601 - val_accuracy: 0.9482\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.2121 - val_accuracy: 0.9459\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 0.2108 - val_accuracy: 0.9527\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.1732 - val_accuracy: 0.9505\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.1366 - val_accuracy: 0.9617\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.1446 - val_accuracy: 0.9640\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0164 - accuracy: 0.9938 - val_loss: 0.1489 - val_accuracy: 0.9572\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.2472 - val_accuracy: 0.9302\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.1567 - val_accuracy: 0.9572\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1292 - val_accuracy: 0.9662\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.1614 - val_accuracy: 0.9550\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 1.0792 - val_accuracy: 0.7545\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.0205 - accuracy: 0.9904 - val_loss: 0.1365 - val_accuracy: 0.9640\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.5607 - val_accuracy: 0.8919\n",
      "18/18 - 1s - loss: 0.6326 - accuracy: 0.8919 - 872ms/epoch - 48ms/step\n",
      "\n",
      "Test accuracy: 0.8918918967247009\n",
      "18/18 [==============================] - 2s 42ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.87      1.00      0.93       399\n",
      "    landslide       1.00      0.62      0.76       156\n",
      "\n",
      "     accuracy                           0.89       555\n",
      "    macro avg       0.93      0.81      0.85       555\n",
      " weighted avg       0.91      0.89      0.88       555\n",
      "\n",
      "Accuracy: 0.6431848064280496\n",
      "Precision: 0.6153846153846154\n",
      "Recall: 0.6153846153846154\n",
      "F1 Score: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用DenseNet121）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用VGG16）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = VGG16(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e57b038-7e01-441e-9533-4dbb015a4922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 20s 175ms/step - loss: 0.7515 - accuracy: 0.8681 - val_loss: 175.0231 - val_accuracy: 0.7995\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1565 - accuracy: 0.9425 - val_loss: 2.4889 - val_accuracy: 0.6059\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1522 - accuracy: 0.9521 - val_loss: 0.6890 - val_accuracy: 0.8581\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1372 - accuracy: 0.9521 - val_loss: 3.1664 - val_accuracy: 0.6869\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0896 - accuracy: 0.9667 - val_loss: 0.3454 - val_accuracy: 0.8919\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1302 - accuracy: 0.9521 - val_loss: 0.7794 - val_accuracy: 0.8446\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0733 - accuracy: 0.9735 - val_loss: 0.5532 - val_accuracy: 0.8378\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0691 - accuracy: 0.9758 - val_loss: 1.7282 - val_accuracy: 0.6622\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0753 - accuracy: 0.9690 - val_loss: 0.4908 - val_accuracy: 0.8829\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0778 - accuracy: 0.9752 - val_loss: 0.3817 - val_accuracy: 0.8288\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.5696 - val_accuracy: 0.7860\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0735 - accuracy: 0.9729 - val_loss: 0.2231 - val_accuracy: 0.9324\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.0553 - accuracy: 0.9775 - val_loss: 0.4409 - val_accuracy: 0.9212\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.4811 - val_accuracy: 0.8491\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0548 - accuracy: 0.9803 - val_loss: 0.1286 - val_accuracy: 0.9550\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.2016 - val_accuracy: 0.9482\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0598 - accuracy: 0.9786 - val_loss: 0.1891 - val_accuracy: 0.9279\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0356 - accuracy: 0.9865 - val_loss: 0.3975 - val_accuracy: 0.8896\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0248 - accuracy: 0.9904 - val_loss: 0.0846 - val_accuracy: 0.9707\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0668 - accuracy: 0.9808 - val_loss: 0.3672 - val_accuracy: 0.8288\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0627 - accuracy: 0.9769 - val_loss: 0.2730 - val_accuracy: 0.9414\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.0420 - accuracy: 0.9837 - val_loss: 0.1949 - val_accuracy: 0.9369\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.1912 - val_accuracy: 0.9459\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0354 - accuracy: 0.9870 - val_loss: 0.4116 - val_accuracy: 0.9009\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.3211 - val_accuracy: 0.9234\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.1957 - val_accuracy: 0.9527\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.4745 - val_accuracy: 0.9144\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0395 - accuracy: 0.9837 - val_loss: 0.1474 - val_accuracy: 0.9482\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 0.3013 - val_accuracy: 0.8941\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0945 - val_accuracy: 0.9685\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.1867 - val_accuracy: 0.9685\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0299 - accuracy: 0.9927 - val_loss: 0.2808 - val_accuracy: 0.9392\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0524 - accuracy: 0.9808 - val_loss: 0.2159 - val_accuracy: 0.9347\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0301 - accuracy: 0.9876 - val_loss: 0.3633 - val_accuracy: 0.8896\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.1732 - val_accuracy: 0.9527\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0301 - accuracy: 0.9859 - val_loss: 0.3404 - val_accuracy: 0.9369\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0380 - accuracy: 0.9865 - val_loss: 0.3480 - val_accuracy: 0.9414\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.1623 - val_accuracy: 0.9505\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.2762 - val_accuracy: 0.9437\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.4989 - val_accuracy: 0.9054\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 1.2899 - val_accuracy: 0.8041\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.0112 - accuracy: 0.9955 - val_loss: 0.2315 - val_accuracy: 0.9459\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0231 - accuracy: 0.9904 - val_loss: 0.3440 - val_accuracy: 0.9032\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1349 - val_accuracy: 0.9527\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.2526 - val_accuracy: 0.9572\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0403 - accuracy: 0.9853 - val_loss: 0.1715 - val_accuracy: 0.9482\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0518 - accuracy: 0.9791 - val_loss: 0.1994 - val_accuracy: 0.9550\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.1583 - val_accuracy: 0.9482\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.1577 - val_accuracy: 0.9550\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.8799 - val_accuracy: 0.8626\n",
      "18/18 - 1s - loss: 1.1681 - accuracy: 0.8523 - 839ms/epoch - 47ms/step\n",
      "\n",
      "Test accuracy: 0.8522522449493408\n",
      "18/18 [==============================] - 2s 43ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.83      0.99      0.91       399\n",
      "    landslide       0.97      0.49      0.65       156\n",
      "\n",
      "     accuracy                           0.85       555\n",
      "    macro avg       0.90      0.74      0.78       555\n",
      " weighted avg       0.87      0.85      0.83       555\n",
      "\n",
      "Accuracy: 0.6573849525200877\n",
      "Precision: 0.48717948717948717\n",
      "Recall: 0.48717948717948717\n",
      "F1 Score: 0.48717948717948717\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用DenseNet121）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用VGG16）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = VGG16(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caa243c-a5d4-4ed4-80d0-944fa31fbeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 19s 178ms/step - loss: 0.2900 - accuracy: 0.8895 - val_loss: 143.5713 - val_accuracy: 0.2477\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.1653 - accuracy: 0.9425 - val_loss: 47.4714 - val_accuracy: 0.7545\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0984 - accuracy: 0.9679 - val_loss: 1.7920 - val_accuracy: 0.6036\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0990 - accuracy: 0.9673 - val_loss: 2.1073 - val_accuracy: 0.7523\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0952 - accuracy: 0.9611 - val_loss: 2.0565 - val_accuracy: 0.7793\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0748 - accuracy: 0.9735 - val_loss: 1.7113 - val_accuracy: 0.8153\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.9559 - val_accuracy: 0.8874\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0668 - accuracy: 0.9752 - val_loss: 1.5929 - val_accuracy: 0.7838\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.4774 - val_accuracy: 0.9077\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 0.0989 - val_accuracy: 0.9730\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.1516 - val_accuracy: 0.9572\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0801 - accuracy: 0.9769 - val_loss: 0.1747 - val_accuracy: 0.9572\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.3899 - val_accuracy: 0.8784\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0862 - accuracy: 0.9701 - val_loss: 0.3883 - val_accuracy: 0.9009\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0472 - accuracy: 0.9814 - val_loss: 0.3965 - val_accuracy: 0.8964\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.2748 - val_accuracy: 0.8964\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0313 - accuracy: 0.9859 - val_loss: 1.3955 - val_accuracy: 0.8311\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.2616 - val_accuracy: 0.9369\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.1426 - val_accuracy: 0.9595\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 9s 158ms/step - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.5349 - val_accuracy: 0.9077\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 10s 172ms/step - loss: 0.0344 - accuracy: 0.9870 - val_loss: 0.6425 - val_accuracy: 0.9099\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1378 - val_accuracy: 0.9617\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.1600 - val_accuracy: 0.9595\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.3065 - val_accuracy: 0.9302\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.3614 - val_accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.0602 - accuracy: 0.9820 - val_loss: 0.1701 - val_accuracy: 0.9459\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 0.2937 - val_accuracy: 0.9279\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.2058 - val_accuracy: 0.9595\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.1923 - val_accuracy: 0.9392\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.5208 - val_accuracy: 0.8986\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.2126 - val_accuracy: 0.9392\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0752 - accuracy: 0.9746 - val_loss: 0.2232 - val_accuracy: 0.9392\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.2345 - val_accuracy: 0.9482\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.4166 - val_accuracy: 0.9212\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1722 - val_accuracy: 0.9617\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1672 - val_accuracy: 0.9617\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.2515 - val_accuracy: 0.9414\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.1464 - val_accuracy: 0.9595\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0095 - accuracy: 0.9949 - val_loss: 0.1591 - val_accuracy: 0.9505\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1497 - val_accuracy: 0.9595\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0311 - accuracy: 0.9932 - val_loss: 0.2958 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.1588 - val_accuracy: 0.9505\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.3490 - val_accuracy: 0.9077\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.1209 - val_accuracy: 0.9707\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.1997 - val_accuracy: 0.9482\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.2646 - val_accuracy: 0.9347\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 2.0072 - val_accuracy: 0.7680\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0336 - accuracy: 0.9876 - val_loss: 0.1471 - val_accuracy: 0.9617\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1161 - val_accuracy: 0.9550\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.1010 - val_accuracy: 0.9752\n",
      "18/18 - 1s - loss: 0.2057 - accuracy: 0.9495 - 637ms/epoch - 35ms/step\n",
      "\n",
      "Test accuracy: 0.9495495557785034\n",
      "18/18 [==============================] - 2s 38ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.96      0.96      0.96       399\n",
      "    landslide       0.91      0.91      0.91       156\n",
      "\n",
      "     accuracy                           0.95       555\n",
      "    macro avg       0.94      0.94      0.94       555\n",
      " weighted avg       0.95      0.95      0.95       555\n",
      "\n",
      "Accuracy: 0.5958509861212564\n",
      "Precision: 0.9102564102564102\n",
      "Recall: 0.9102564102564102\n",
      "F1 Score: 0.9102564102564102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用InceptionV3）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用MobileNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa52756-c352-47ce-86d7-c700b045f11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 19s 176ms/step - loss: 6.8157 - accuracy: 0.8760 - val_loss: 9.2504 - val_accuracy: 0.7410\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.1531 - accuracy: 0.9436 - val_loss: 0.9907 - val_accuracy: 0.8851\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.1869 - accuracy: 0.9340 - val_loss: 0.2146 - val_accuracy: 0.9302\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.1234 - accuracy: 0.9549 - val_loss: 0.2582 - val_accuracy: 0.9009\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.1059 - accuracy: 0.9600 - val_loss: 0.4798 - val_accuracy: 0.9009\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 9s 154ms/step - loss: 0.0717 - accuracy: 0.9729 - val_loss: 1.0122 - val_accuracy: 0.7410\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0957 - accuracy: 0.9713 - val_loss: 0.2300 - val_accuracy: 0.9324\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0954 - accuracy: 0.9662 - val_loss: 0.2741 - val_accuracy: 0.8851\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0637 - accuracy: 0.9797 - val_loss: 0.2195 - val_accuracy: 0.9392\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0503 - accuracy: 0.9786 - val_loss: 0.4749 - val_accuracy: 0.9077\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 8s 152ms/step - loss: 0.1133 - accuracy: 0.9594 - val_loss: 1.6232 - val_accuracy: 0.6396\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0333 - accuracy: 0.9865 - val_loss: 0.1966 - val_accuracy: 0.9550\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.2760 - val_accuracy: 0.9257\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 8s 149ms/step - loss: 0.0738 - accuracy: 0.9724 - val_loss: 0.2985 - val_accuracy: 0.9122\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.6635 - val_accuracy: 0.7793\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0522 - accuracy: 0.9803 - val_loss: 0.1837 - val_accuracy: 0.9550\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0369 - accuracy: 0.9853 - val_loss: 0.4653 - val_accuracy: 0.9189\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 9s 159ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.3454 - val_accuracy: 0.8941\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0542 - accuracy: 0.9820 - val_loss: 0.1858 - val_accuracy: 0.9414\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 9s 155ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.8412 - val_accuracy: 0.8063\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.3646 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.2835 - val_accuracy: 0.9189\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.2243 - val_accuracy: 0.9550\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0534 - accuracy: 0.9803 - val_loss: 0.3173 - val_accuracy: 0.9099\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 9s 162ms/step - loss: 0.0363 - accuracy: 0.9876 - val_loss: 0.1557 - val_accuracy: 0.9572\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.1191 - val_accuracy: 0.9595\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.4912 - val_accuracy: 0.8919\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1653 - val_accuracy: 0.9550\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0722 - accuracy: 0.9769 - val_loss: 0.1884 - val_accuracy: 0.9369\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 0.2291 - val_accuracy: 0.9459\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.3767 - val_accuracy: 0.9212\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 10s 172ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.2322 - val_accuracy: 0.9437\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 10s 173ms/step - loss: 0.0284 - accuracy: 0.9893 - val_loss: 0.2445 - val_accuracy: 0.9482\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 9s 152ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.3360 - val_accuracy: 0.9212\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0550 - accuracy: 0.9797 - val_loss: 0.1205 - val_accuracy: 0.9482\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 0.1456 - val_accuracy: 0.9527\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1693 - val_accuracy: 0.9527\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1234 - val_accuracy: 0.9685\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 9.8832e-04 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9685\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 1.0695 - val_accuracy: 0.8131\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.1054 - val_accuracy: 0.9595\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0181 - accuracy: 0.9955 - val_loss: 0.9899 - val_accuracy: 0.7207\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.2602 - val_accuracy: 0.9324\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 8s 147ms/step - loss: 0.0188 - accuracy: 0.9955 - val_loss: 0.3248 - val_accuracy: 0.9144\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 8s 145ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.2202 - val_accuracy: 0.9437\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.2349 - val_accuracy: 0.9392\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.2484 - val_accuracy: 0.9032\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0276 - accuracy: 0.9893 - val_loss: 0.2470 - val_accuracy: 0.9414\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 9s 153ms/step - loss: 0.0310 - accuracy: 0.9938 - val_loss: 0.4139 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 8s 151ms/step - loss: 0.1034 - accuracy: 0.9724 - val_loss: 0.4848 - val_accuracy: 0.8468\n",
      "18/18 - 1s - loss: 0.4962 - accuracy: 0.8505 - 860ms/epoch - 48ms/step\n",
      "\n",
      "Test accuracy: 0.8504504561424255\n",
      "18/18 [==============================] - 2s 44ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.97      0.81      0.89       399\n",
      "    landslide       0.67      0.94      0.78       156\n",
      "\n",
      "     accuracy                           0.85       555\n",
      "    macro avg       0.82      0.88      0.83       555\n",
      " weighted avg       0.89      0.85      0.86       555\n",
      "\n",
      "Accuracy: 0.544572680788897\n",
      "Precision: 0.9423076923076923\n",
      "Recall: 0.9423076923076923\n",
      "F1 Score: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用DenseNet121）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用VGG16）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = VGG16(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848a626a-b1c5-443e-aaa4-d3d564cf0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 3s 0us/step\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 19s 197ms/step - loss: 7.8709 - accuracy: 0.6714 - val_loss: 2.1752 - val_accuracy: 0.7523\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.6076 - accuracy: 0.7153 - val_loss: 1.6520 - val_accuracy: 0.7523\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.5790 - accuracy: 0.7170 - val_loss: 0.7364 - val_accuracy: 0.7523\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.5680 - accuracy: 0.7198 - val_loss: 0.9486 - val_accuracy: 0.7523\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.5645 - accuracy: 0.7131 - val_loss: 0.7159 - val_accuracy: 0.7523\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.5726 - accuracy: 0.7204 - val_loss: 0.5931 - val_accuracy: 0.7523\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.5890 - accuracy: 0.7159 - val_loss: 0.8447 - val_accuracy: 0.7523\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.5738 - accuracy: 0.7153 - val_loss: 0.5499 - val_accuracy: 0.7523\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 11s 192ms/step - loss: 0.5413 - accuracy: 0.7277 - val_loss: 0.5141 - val_accuracy: 0.7297\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 10s 180ms/step - loss: 0.5639 - accuracy: 0.7148 - val_loss: 0.5364 - val_accuracy: 0.7523\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 10s 184ms/step - loss: 0.5845 - accuracy: 0.7120 - val_loss: 0.5730 - val_accuracy: 0.7523\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 10s 184ms/step - loss: 0.5451 - accuracy: 0.7289 - val_loss: 0.5569 - val_accuracy: 0.7523\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 10s 183ms/step - loss: 0.5249 - accuracy: 0.7317 - val_loss: 0.7242 - val_accuracy: 0.7523\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.4904 - accuracy: 0.7430 - val_loss: 0.5790 - val_accuracy: 0.7523\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 10s 177ms/step - loss: 0.5126 - accuracy: 0.7272 - val_loss: 0.4661 - val_accuracy: 0.7523\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 11s 192ms/step - loss: 0.4810 - accuracy: 0.7260 - val_loss: 0.4993 - val_accuracy: 0.7523\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 10s 179ms/step - loss: 0.4925 - accuracy: 0.7441 - val_loss: 0.4735 - val_accuracy: 0.7523\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.4784 - accuracy: 0.7694 - val_loss: 0.4556 - val_accuracy: 0.7860\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 10s 184ms/step - loss: 0.4664 - accuracy: 0.7672 - val_loss: 0.4448 - val_accuracy: 0.7815\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 11s 187ms/step - loss: 0.4568 - accuracy: 0.7835 - val_loss: 0.4471 - val_accuracy: 0.7793\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.4623 - accuracy: 0.7678 - val_loss: 0.7108 - val_accuracy: 0.7523\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.3863 - accuracy: 0.8202 - val_loss: 0.6093 - val_accuracy: 0.7523\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 10s 183ms/step - loss: 0.4625 - accuracy: 0.7655 - val_loss: 0.4459 - val_accuracy: 0.7725\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.4320 - accuracy: 0.7790 - val_loss: 0.4784 - val_accuracy: 0.7523\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 11s 191ms/step - loss: 0.4199 - accuracy: 0.7982 - val_loss: 0.3812 - val_accuracy: 0.8063\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 11s 201ms/step - loss: 0.3820 - accuracy: 0.8230 - val_loss: 0.4298 - val_accuracy: 0.8063\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 10s 185ms/step - loss: 0.3758 - accuracy: 0.8253 - val_loss: 0.4193 - val_accuracy: 0.7995\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.3649 - accuracy: 0.8303 - val_loss: 0.6441 - val_accuracy: 0.7590\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.3905 - accuracy: 0.8095 - val_loss: 0.6385 - val_accuracy: 0.8041\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 10s 173ms/step - loss: 0.3604 - accuracy: 0.8326 - val_loss: 0.4027 - val_accuracy: 0.7950\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.3177 - accuracy: 0.8613 - val_loss: 0.3519 - val_accuracy: 0.8311\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.3470 - accuracy: 0.8292 - val_loss: 0.3760 - val_accuracy: 0.8401\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.3744 - accuracy: 0.8258 - val_loss: 0.3582 - val_accuracy: 0.8378\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 10s 184ms/step - loss: 0.3021 - accuracy: 0.8726 - val_loss: 0.3716 - val_accuracy: 0.8153\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 10s 182ms/step - loss: 0.3365 - accuracy: 0.8444 - val_loss: 0.3677 - val_accuracy: 0.8536\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.3136 - accuracy: 0.8444 - val_loss: 0.3496 - val_accuracy: 0.8378\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 10s 182ms/step - loss: 0.2870 - accuracy: 0.8715 - val_loss: 0.5391 - val_accuracy: 0.7928\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 11s 191ms/step - loss: 0.2898 - accuracy: 0.8720 - val_loss: 0.6844 - val_accuracy: 0.7770\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.2777 - accuracy: 0.8766 - val_loss: 0.3335 - val_accuracy: 0.8468\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 10s 177ms/step - loss: 0.2474 - accuracy: 0.8890 - val_loss: 0.3164 - val_accuracy: 0.8671\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.2328 - accuracy: 0.9036 - val_loss: 0.5042 - val_accuracy: 0.8198\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.2532 - accuracy: 0.8923 - val_loss: 0.8108 - val_accuracy: 0.6847\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.2250 - accuracy: 0.9030 - val_loss: 0.7298 - val_accuracy: 0.7410\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.2246 - accuracy: 0.9047 - val_loss: 0.8073 - val_accuracy: 0.7523\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.1974 - accuracy: 0.9228 - val_loss: 0.2486 - val_accuracy: 0.8941\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.2108 - accuracy: 0.9121 - val_loss: 0.3497 - val_accuracy: 0.8806\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 10s 177ms/step - loss: 0.1949 - accuracy: 0.9222 - val_loss: 0.2926 - val_accuracy: 0.8784\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 10s 185ms/step - loss: 0.1645 - accuracy: 0.9357 - val_loss: 0.3618 - val_accuracy: 0.8536\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 10s 180ms/step - loss: 0.2213 - accuracy: 0.9121 - val_loss: 0.2551 - val_accuracy: 0.8919\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.1800 - accuracy: 0.9278 - val_loss: 0.2722 - val_accuracy: 0.8896\n",
      "18/18 - 1s - loss: 0.3033 - accuracy: 0.8775 - 811ms/epoch - 45ms/step\n",
      "\n",
      "Test accuracy: 0.8774774670600891\n",
      "18/18 [==============================] - 1s 36ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.94      0.88      0.91       399\n",
      "    landslide       0.74      0.87      0.80       156\n",
      "\n",
      "     accuracy                           0.88       555\n",
      "    macro avg       0.84      0.87      0.86       555\n",
      " weighted avg       0.89      0.88      0.88       555\n",
      "\n",
      "Accuracy: 0.5753396639883126\n",
      "Precision: 0.8653846153846154\n",
      "Recall: 0.8653846153846154\n",
      "F1 Score: 0.8653846153846154\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用VGG19）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = VGG19(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用MobileNetV2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b379ec50-80f8-4eb6-8cbf-15a36807c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 13:34:26.356605: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 13:34:39.622451: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 13:34:40.061789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22134 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:39:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 13:35:01.083177: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-05-13 13:35:01.742881: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-05-13 13:35:01.742895: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-05-13 13:35:01.742940: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-13 13:35:02.814401: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 31s 224ms/step - loss: 0.3265 - accuracy: 0.8822 - val_loss: 3.5029 - val_accuracy: 0.7568\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.1473 - accuracy: 0.9498 - val_loss: 5.2990 - val_accuracy: 0.8333\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0979 - accuracy: 0.9634 - val_loss: 0.5697 - val_accuracy: 0.8446\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.0992 - accuracy: 0.9628 - val_loss: 0.5546 - val_accuracy: 0.8401\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0789 - accuracy: 0.9707 - val_loss: 0.2883 - val_accuracy: 0.9279\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.0644 - accuracy: 0.9769 - val_loss: 0.2000 - val_accuracy: 0.9414\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.1110 - accuracy: 0.9605 - val_loss: 0.2846 - val_accuracy: 0.8941\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0741 - accuracy: 0.9741 - val_loss: 4.8476 - val_accuracy: 0.7860\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.0480 - accuracy: 0.9837 - val_loss: 0.1885 - val_accuracy: 0.9437\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0407 - accuracy: 0.9848 - val_loss: 0.5740 - val_accuracy: 0.8784\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0501 - accuracy: 0.9870 - val_loss: 0.1853 - val_accuracy: 0.9527\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.1556 - val_accuracy: 0.9459\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0391 - accuracy: 0.9910 - val_loss: 0.1679 - val_accuracy: 0.9640\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 9s 157ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.1379 - val_accuracy: 0.9640\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.3060 - val_accuracy: 0.9324\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 8s 148ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1207 - val_accuracy: 0.9685\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 2.6970 - val_accuracy: 0.7387\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.1173 - val_accuracy: 0.9707\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.0357 - accuracy: 0.9904 - val_loss: 1.5580 - val_accuracy: 0.7793\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.4095 - val_accuracy: 0.9212\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 9s 168ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.2532 - val_accuracy: 0.9459\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 10s 172ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.1821 - val_accuracy: 0.9617\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.4474 - val_accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 10s 173ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.3144 - val_accuracy: 0.9459\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1543 - val_accuracy: 0.9662\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 10s 175ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.2000 - val_accuracy: 0.9437\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 10s 174ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.2798 - val_accuracy: 0.9369\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.1845 - val_accuracy: 0.9505\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 0.3246 - val_accuracy: 0.8919\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 0.0196 - accuracy: 0.9915 - val_loss: 0.1649 - val_accuracy: 0.9505\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1769 - val_accuracy: 0.9572\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.1537 - val_accuracy: 0.9685\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 8s 150ms/step - loss: 0.0711 - accuracy: 0.9724 - val_loss: 2.1065 - val_accuracy: 0.4775\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 9s 167ms/step - loss: 0.0319 - accuracy: 0.9865 - val_loss: 0.2923 - val_accuracy: 0.9302\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 9s 163ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.1082 - val_accuracy: 0.9707\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 8s 144ms/step - loss: 0.0192 - accuracy: 0.9955 - val_loss: 0.1085 - val_accuracy: 0.9685\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.1872 - val_accuracy: 0.9505\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 0.1814 - val_accuracy: 0.9437\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1084 - val_accuracy: 0.9707\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 9s 161ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0801 - val_accuracy: 0.9730\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 9s 169ms/step - loss: 7.5420e-04 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9752\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 1.6320e-04 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9685\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 8s 141ms/step - loss: 7.6461e-05 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9730\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 1.5162e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9685\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 7.1058e-05 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9662\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 9.4602e-05 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9685\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 4.0829e-05 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9685\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 9.8943e-05 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9662\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 9s 160ms/step - loss: 5.1190e-04 - accuracy: 0.9994 - val_loss: 0.1330 - val_accuracy: 0.9685\n",
      "18/18 - 1s - loss: 0.1392 - accuracy: 0.9676 - 1s/epoch - 81ms/step\n",
      "\n",
      "Test accuracy: 0.9675675630569458\n",
      "18/18 [==============================] - 3s 45ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.99      0.96      0.98       399\n",
      "    landslide       0.91      0.98      0.94       156\n",
      "\n",
      "     accuracy                           0.97       555\n",
      "    macro avg       0.95      0.97      0.96       555\n",
      " weighted avg       0.97      0.97      0.97       555\n",
      "\n",
      "Accuracy: 0.5863842220598977\n",
      "Precision: 0.9807692307692307\n",
      "Recall: 0.9807692307692307\n",
      "F1 Score: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3, DenseNet121\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用InceptionV3）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用DenseNet121）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = DenseNet121(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b5e443-35a2-4bfb-a3a1-d29eb26bceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 26s 286ms/step - loss: 0.2662 - accuracy: 0.8952 - val_loss: 6.6084 - val_accuracy: 0.2680\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 0.1125 - accuracy: 0.9605 - val_loss: 10.7866 - val_accuracy: 0.2477\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 0.0826 - accuracy: 0.9741 - val_loss: 10.5499 - val_accuracy: 0.2477\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 0.0893 - accuracy: 0.9718 - val_loss: 10.9711 - val_accuracy: 0.2477\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 13s 235ms/step - loss: 0.1005 - accuracy: 0.9656 - val_loss: 8.3066 - val_accuracy: 0.4144\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0650 - accuracy: 0.9808 - val_loss: 9.6522 - val_accuracy: 0.2568\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 16.1590 - val_accuracy: 0.3311\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 7.3461 - val_accuracy: 0.4797\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 0.0399 - accuracy: 0.9848 - val_loss: 15.0850 - val_accuracy: 0.2815\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0350 - accuracy: 0.9876 - val_loss: 5.1609 - val_accuracy: 0.7635\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 3.5082 - val_accuracy: 0.7770\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 5.2850 - val_accuracy: 0.7185\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 3.2004 - val_accuracy: 0.7590\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 5.1569 - val_accuracy: 0.5158\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 14s 247ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 5.4469 - val_accuracy: 0.5338\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0260 - accuracy: 0.9904 - val_loss: 14.4864 - val_accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 13s 229ms/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 12.8731 - val_accuracy: 0.2860\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 13s 227ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 4.2103 - val_accuracy: 0.6869\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 13s 228ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 4.2238 - val_accuracy: 0.7140\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 13s 233ms/step - loss: 8.4756e-04 - accuracy: 1.0000 - val_loss: 4.8922 - val_accuracy: 0.7050\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 6.1958 - val_accuracy: 0.5135\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 2.4371 - val_accuracy: 0.6734\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 13s 228ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 6.3877 - val_accuracy: 0.4640\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 13s 227ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 3.5432 - val_accuracy: 0.7973\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 3.3276 - val_accuracy: 0.7117\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 1.4382 - val_accuracy: 0.8356\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 13s 237ms/step - loss: 0.0310 - accuracy: 0.9927 - val_loss: 10.5634 - val_accuracy: 0.2748\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 13s 234ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 1.8320 - val_accuracy: 0.7838\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 13s 225ms/step - loss: 0.0036 - accuracy: 0.9983 - val_loss: 1.8609 - val_accuracy: 0.7928\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 13s 229ms/step - loss: 0.0240 - accuracy: 0.9904 - val_loss: 2.0497 - val_accuracy: 0.8491\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 13s 226ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 3.3526 - val_accuracy: 0.7793\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 0.0575 - accuracy: 0.9848 - val_loss: 2.1128 - val_accuracy: 0.8311\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 14s 253ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 3.1145 - val_accuracy: 0.7928\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 14s 250ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 3.2816 - val_accuracy: 0.8041\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 1.3703 - val_accuracy: 0.8784\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 14s 252ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 4.2782 - val_accuracy: 0.7883\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 2.2770 - val_accuracy: 0.7860\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 13s 226ms/step - loss: 0.0243 - accuracy: 0.9893 - val_loss: 1.8887 - val_accuracy: 0.8378\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 13s 228ms/step - loss: 0.0170 - accuracy: 0.9921 - val_loss: 3.7623 - val_accuracy: 0.5158\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 13s 226ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 7.8506 - val_accuracy: 0.5158\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 13s 233ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.8973 - val_accuracy: 0.8221\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.7998 - val_accuracy: 0.9189\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 1.1216 - val_accuracy: 0.8604\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 13s 234ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.9280 - val_accuracy: 0.9122\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 13s 233ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 1.6102 - val_accuracy: 0.8941\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 14s 241ms/step - loss: 2.1328e-04 - accuracy: 1.0000 - val_loss: 1.4116 - val_accuracy: 0.8986\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 14s 246ms/step - loss: 1.6622e-04 - accuracy: 1.0000 - val_loss: 1.0286 - val_accuracy: 0.9144\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 13s 235ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 2.0864 - val_accuracy: 0.8356\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 13s 234ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 21.2807 - val_accuracy: 0.3581\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 13s 231ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 6.4058 - val_accuracy: 0.6757\n",
      "18/18 - 1s - loss: 6.8317 - accuracy: 0.6577 - 900ms/epoch - 50ms/step\n",
      "\n",
      "Test accuracy: 0.6576576828956604\n",
      "18/18 [==============================] - 2s 35ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.99      0.53      0.69       399\n",
      "    landslide       0.45      0.98      0.62       156\n",
      "\n",
      "     accuracy                           0.66       555\n",
      "    macro avg       0.72      0.76      0.65       555\n",
      " weighted avg       0.84      0.66      0.67       555\n",
      "\n",
      "Accuracy: 0.45069393718042366\n",
      "Precision: 0.9807692307692307\n",
      "Recall: 0.9807692307692307\n",
      "F1 Score: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用MobileNetV2）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用Xception）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = Xception(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8005b5d-839f-4bd8-bb39-d6c7d139044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234545216/234545216 [==============================] - 9s 0us/step\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 36s 303ms/step - loss: 0.2331 - accuracy: 0.9166 - val_loss: 0.4108 - val_accuracy: 0.9099\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 13s 233ms/step - loss: 0.0940 - accuracy: 0.9707 - val_loss: 0.1393 - val_accuracy: 0.9752\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 0.0415 - accuracy: 0.9848 - val_loss: 0.1198 - val_accuracy: 0.9685\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 14s 254ms/step - loss: 0.0586 - accuracy: 0.9769 - val_loss: 0.0478 - val_accuracy: 0.9865\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 14s 255ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.1212 - val_accuracy: 0.9730\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 0.0634 - val_accuracy: 0.9662\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.1305 - val_accuracy: 0.9707\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0592 - val_accuracy: 0.9797\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 13s 239ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0836 - val_accuracy: 0.9730\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.1381 - val_accuracy: 0.9797\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0340 - accuracy: 0.9910 - val_loss: 0.1348 - val_accuracy: 0.9662\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 13s 240ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.0633 - val_accuracy: 0.9775\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 13s 227ms/step - loss: 0.0209 - accuracy: 0.9955 - val_loss: 0.0775 - val_accuracy: 0.9775\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 13s 227ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.2590 - val_accuracy: 0.9617\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 13s 229ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.1126 - val_accuracy: 0.9820\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.1457 - val_accuracy: 0.9730\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0303 - accuracy: 0.9876 - val_loss: 0.0849 - val_accuracy: 0.9752\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 13s 238ms/step - loss: 0.0239 - accuracy: 0.9899 - val_loss: 0.0712 - val_accuracy: 0.9752\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.0844 - val_accuracy: 0.9797\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.6392 - val_accuracy: 0.8919\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0540 - val_accuracy: 0.9842\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 13s 229ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1163 - val_accuracy: 0.9730\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 13s 231ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0979 - val_accuracy: 0.9730\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 13s 228ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0729 - val_accuracy: 0.9797\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0596 - val_accuracy: 0.9797\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0083 - accuracy: 0.9961 - val_loss: 0.0660 - val_accuracy: 0.9842\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 13s 230ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0700 - val_accuracy: 0.9842\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 13s 234ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.0815 - val_accuracy: 0.9865\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.1159 - val_accuracy: 0.9685\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0665 - val_accuracy: 0.9797\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 13s 226ms/step - loss: 0.0602 - accuracy: 0.9780 - val_loss: 0.0829 - val_accuracy: 0.9842\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 13s 231ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.1162 - val_accuracy: 0.9752\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 14s 248ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.0914 - val_accuracy: 0.9662\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 14s 244ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0365 - val_accuracy: 0.9887\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0119 - accuracy: 0.9955 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0474 - val_accuracy: 0.9932\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 14s 251ms/step - loss: 4.1933e-04 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9932\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 14s 249ms/step - loss: 5.6989e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9865\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 13s 234ms/step - loss: 1.1578e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9865\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 13s 229ms/step - loss: 1.8279e-04 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 13s 236ms/step - loss: 1.2904e-04 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 0.0035 - accuracy: 0.9977 - val_loss: 0.0727 - val_accuracy: 0.9887\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 14s 242ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 0.0970 - val_accuracy: 0.9797\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 13s 233ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 13s 241ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1257 - val_accuracy: 0.9842\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 14s 245ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.0926 - val_accuracy: 0.9842\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 13s 231ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0950 - val_accuracy: 0.9797\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 14s 243ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0955 - val_accuracy: 0.9775\n",
      "18/18 - 1s - loss: 0.2105 - accuracy: 0.9550 - 1s/epoch - 73ms/step\n",
      "\n",
      "Test accuracy: 0.954954981803894\n",
      "18/18 [==============================] - 4s 58ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.98      0.95      0.97       399\n",
      "    landslide       0.89      0.96      0.92       156\n",
      "\n",
      "     accuracy                           0.95       555\n",
      "    macro avg       0.94      0.96      0.95       555\n",
      " weighted avg       0.96      0.95      0.96       555\n",
      "\n",
      "Accuracy: 0.5855953250547845\n",
      "Precision: 0.9615384615384616\n",
      "Recall: 0.9615384615384616\n",
      "F1 Score: 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet152V2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用EfficientNetB0）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用ResNet152V2）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = ResNet152V2(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ece6b9-3060-47e4-be58-b995c915f261",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "19993432/19993432 [==============================] - 2s 0us/step\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 384ms/step - loss: 0.2333 - accuracy: 0.9126 - val_loss: 20.8696 - val_accuracy: 0.2477\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 17s 308ms/step - loss: 0.0786 - accuracy: 0.9763 - val_loss: 899.4100 - val_accuracy: 0.2477\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 17s 310ms/step - loss: 0.0671 - accuracy: 0.9797 - val_loss: 17.3617 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 17s 311ms/step - loss: 0.0412 - accuracy: 0.9853 - val_loss: 641.7869 - val_accuracy: 0.2658\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 17s 308ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 18.7561 - val_accuracy: 0.5766\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 17s 311ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 197.5278 - val_accuracy: 0.2725\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 17s 306ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 14.8166 - val_accuracy: 0.7477\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 17s 307ms/step - loss: 0.0262 - accuracy: 0.9899 - val_loss: 4.4655 - val_accuracy: 0.7230\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 18s 313ms/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 3.7637 - val_accuracy: 0.7883\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 18s 313ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 6.4588 - val_accuracy: 0.7477\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 17s 305ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 2.8841 - val_accuracy: 0.7387\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 18s 313ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 935.5717 - val_accuracy: 0.2770\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 238.2560 - val_accuracy: 0.6059\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 17s 307ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 39.3173 - val_accuracy: 0.7432\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 18s 313ms/step - loss: 0.1030 - accuracy: 0.9645 - val_loss: 183.0874 - val_accuracy: 0.5991\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 19s 330ms/step - loss: 0.0395 - accuracy: 0.9899 - val_loss: 430.0921 - val_accuracy: 0.5608\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 18s 314ms/step - loss: 0.0080 - accuracy: 0.9966 - val_loss: 151.7729 - val_accuracy: 0.7523\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 18s 314ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 220.6913 - val_accuracy: 0.3694\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 18s 322ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 224.3221 - val_accuracy: 0.4054\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 18s 324ms/step - loss: 0.0269 - accuracy: 0.9949 - val_loss: 1410.3287 - val_accuracy: 0.3086\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 18s 314ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 491.4480 - val_accuracy: 0.4459\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 17s 307ms/step - loss: 0.0514 - accuracy: 0.9831 - val_loss: 523.2111 - val_accuracy: 0.7523\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 17s 312ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 625.9583 - val_accuracy: 0.3401\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 18s 315ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 359.6785 - val_accuracy: 0.3086\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 17s 313ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 266.7376 - val_accuracy: 0.2477\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 18s 313ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 715.3846 - val_accuracy: 0.2477\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 17s 304ms/step - loss: 0.0322 - accuracy: 0.9921 - val_loss: 270.6526 - val_accuracy: 0.2477\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 100.1582 - val_accuracy: 0.2477\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 17s 311ms/step - loss: 6.1412e-04 - accuracy: 1.0000 - val_loss: 106.4810 - val_accuracy: 0.2477\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 18s 322ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 35.8995 - val_accuracy: 0.2793\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 17s 312ms/step - loss: 0.0043 - accuracy: 0.9977 - val_loss: 18.3248 - val_accuracy: 0.3378\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 19s 341ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 40.3049 - val_accuracy: 0.2432\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 19s 338ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 30.0320 - val_accuracy: 0.2342\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 18s 321ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 21.9265 - val_accuracy: 0.2568\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 18s 321ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 19.2346 - val_accuracy: 0.2545\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 17s 306ms/step - loss: 2.3504e-04 - accuracy: 1.0000 - val_loss: 11.4901 - val_accuracy: 0.2883\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 17s 306ms/step - loss: 1.1419e-04 - accuracy: 1.0000 - val_loss: 9.4777 - val_accuracy: 0.3423\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 17s 308ms/step - loss: 1.2609e-04 - accuracy: 1.0000 - val_loss: 5.0820 - val_accuracy: 0.5766\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 17s 310ms/step - loss: 3.1978e-04 - accuracy: 1.0000 - val_loss: 5.9488 - val_accuracy: 0.5563\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 5.2016 - val_accuracy: 0.5766\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 18s 326ms/step - loss: 2.0212e-04 - accuracy: 1.0000 - val_loss: 10.5922 - val_accuracy: 0.2973\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 6.4512e-05 - accuracy: 1.0000 - val_loss: 7.0659 - val_accuracy: 0.3604\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 18s 313ms/step - loss: 1.4679e-05 - accuracy: 1.0000 - val_loss: 5.8481 - val_accuracy: 0.3941\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 18s 324ms/step - loss: 8.6093e-05 - accuracy: 1.0000 - val_loss: 6.1581 - val_accuracy: 0.3761\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 19s 331ms/step - loss: 1.2329e-05 - accuracy: 1.0000 - val_loss: 6.5829 - val_accuracy: 0.3626\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 1.6626e-05 - accuracy: 1.0000 - val_loss: 5.4273 - val_accuracy: 0.4144\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 17s 310ms/step - loss: 2.0168e-06 - accuracy: 1.0000 - val_loss: 4.7275 - val_accuracy: 0.4662\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 17s 312ms/step - loss: 1.6059e-05 - accuracy: 1.0000 - val_loss: 4.4870 - val_accuracy: 0.4865\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 17s 311ms/step - loss: 5.1574e-06 - accuracy: 1.0000 - val_loss: 4.0595 - val_accuracy: 0.5383\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 17s 309ms/step - loss: 3.3443e-06 - accuracy: 1.0000 - val_loss: 3.7573 - val_accuracy: 0.5721\n",
      "18/18 - 1s - loss: 3.7473 - accuracy: 0.5928 - 1s/epoch - 57ms/step\n",
      "\n",
      "Test accuracy: 0.592792809009552\n",
      "18/18 [==============================] - 4s 52ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non-landslide       0.68      0.81      0.74       399\n",
      "    landslide       0.08      0.04      0.06       156\n",
      "\n",
      "     accuracy                           0.59       555\n",
      "    macro avg       0.38      0.43      0.40       555\n",
      " weighted avg       0.51      0.59      0.55       555\n",
      "\n",
      "Accuracy: 0.6526515704894084\n",
      "Precision: 0.04487179487179487\n",
      "Recall: 0.04487179487179487\n",
      "F1 Score: 0.04487179487179487\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import NASNetMobile, Xception\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = \"Bijie_landslide_dataset/Bijie-landslide-dataset\"\n",
    "\n",
    "# 定义数据生成器\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 加载数据集\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# 加载landslide数据\n",
    "landslide_dir = os.path.join(data_dir, \"landslide\")\n",
    "landslide_dem_dir = os.path.join(landslide_dir, \"dem\")\n",
    "landslide_image_dir = os.path.join(landslide_dir, \"image\")\n",
    "landslide_mask_dir = os.path.join(landslide_dir, \"mask\")\n",
    "\n",
    "# 加载non-landslide数据\n",
    "non_landslide_dir = os.path.join(data_dir, \"non-landslide\")\n",
    "non_landslide_dem_dir = os.path.join(non_landslide_dir, \"dem\")\n",
    "non_landslide_image_dir = os.path.join(non_landslide_dir, \"image\")\n",
    "\n",
    "# 读取并预处理数据函数\n",
    "def read_and_preprocess_data(image_dir, dem_dir=None):\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if not filename.startswith('.')]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=(image_height, image_width)) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img) for img in images]\n",
    "    images = np.array(images)\n",
    "\n",
    "    if dem_dir:\n",
    "        dem_paths = [os.path.join(dem_dir, filename) for filename in os.listdir(dem_dir) if not filename.startswith('.')]\n",
    "        dem_images = [tf.keras.preprocessing.image.load_img(dem_path, target_size=(image_height, image_width)) for dem_path in dem_paths]\n",
    "        dem_images = [tf.keras.preprocessing.image.img_to_array(dem) for dem in dem_images]\n",
    "        dem_images = np.array(dem_images)\n",
    "        return images, dem_images\n",
    "    else:\n",
    "        return images\n",
    "\n",
    "# 读取并预处理landslide数据\n",
    "landslide_images, landslide_dem_images = read_and_preprocess_data(landslide_image_dir, landslide_dem_dir)\n",
    "landslide_labels = np.ones(len(landslide_images))\n",
    "\n",
    "# 读取并预处理non-landslide数据\n",
    "non_landslide_images = read_and_preprocess_data(non_landslide_image_dir)\n",
    "non_landslide_labels = np.zeros(len(non_landslide_images))\n",
    "\n",
    "# 合并数据集\n",
    "images = np.concatenate((landslide_images, non_landslide_images), axis=0)\n",
    "dem_images = np.concatenate((landslide_dem_images, np.zeros_like(non_landslide_images)), axis=0)  # 对于non-landslide数据，DEM图像全为0\n",
    "labels = np.concatenate((landslide_labels, non_landslide_labels), axis=0)\n",
    "\n",
    "# 切分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建图像处理模型（使用NASNetMobile）\n",
    "input_image = Input(shape=(image_height, image_width, 3))\n",
    "base_model_image = NASNetMobile(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "image_features = GlobalAveragePooling2D()(base_model_image.output)\n",
    "image_output = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "# 构建DEM处理模型（使用Xception）\n",
    "input_dem = Input(shape=(image_height, image_width, 3))\n",
    "base_model_dem = Xception(include_top=False, weights='imagenet', input_tensor=input_dem)\n",
    "dem_features = GlobalAveragePooling2D()(base_model_dem.output)\n",
    "dem_output = Dense(256, activation='relu')(dem_features)\n",
    "\n",
    "# 将两个模型输出连接\n",
    "merged = Concatenate()([image_output, dem_output])\n",
    "\n",
    "# 最终的分类层\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=[input_image, input_dem], outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train, dem_images[:len(X_train)]], y_train, batch_size=batch_size, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate([X_test, dem_images[len(X_train):]], y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = model.predict([X_test, dem_images[len(X_train):]])\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "# 输出性能报告结果\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['non-landslide', 'landslide'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 输出其他性能指标\n",
    "accuracy = np.mean(y_test == y_pred_classes)\n",
    "precision = np.mean(y_pred_classes[y_test == 1] == 1)\n",
    "recall = np.mean(y_pred_classes[y_test == 1] == y_test[y_test == 1])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c87f1-0b19-4468-8fa4-c4761f4416e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
